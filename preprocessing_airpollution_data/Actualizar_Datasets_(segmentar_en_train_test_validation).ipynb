{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SuAkpPKsW9UQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convertir_ugm3_a_ppb(ugm3, peso_molecular):\n",
        "    # 24.45 es el volumen molar del gas ideal a 25°C y 1 atm en L/mol\n",
        "    volumen_molar = 24.45\n",
        "    ppb = (ugm3 * volumen_molar) / peso_molecular\n",
        "    return ppb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Selección de datos para analisis de tráfico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "dir_raw_data = \"C:/Users/valer/Documents/CIC/doctorado/air_pollution/preprocessing_airpollution_data/all_data_2005xstation_31_05_2024\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ACO.csv 0\n",
            "AJM.csv 2359\n",
            "AJU.csv 2214\n",
            "ARA.csv 0\n",
            "ATI.csv 2316\n",
            "AZC.csv 0\n",
            "BJU.csv 2302\n",
            "CAM.csv 2101\n",
            "CCA.csv 2300\n",
            "CES.csv 0\n",
            "CHO.csv 1876\n",
            "COY.csv 0\n",
            "CUA.csv 2317\n",
            "CUT.csv 2344\n",
            "FAC.csv 2318\n",
            "FAR.csv 2345\n",
            "GAM.csv 2355\n",
            "HGM.csv 1773\n",
            "IMP.csv 0\n",
            "INN.csv 2323\n",
            "IZT.csv 2323\n",
            "LAG.csv 0\n",
            "LLA.csv 2286\n",
            "LPR.csv 2253\n",
            "MER.csv 2231\n",
            "MGH.csv 2359\n",
            "MON.csv 2263\n",
            "MPA.csv 2333\n",
            "NEZ.csv 2356\n",
            "PED.csv 2201\n",
            "PLA.csv 0\n",
            "SAC.csv 2364\n",
            "SAG.csv 2226\n",
            "SFE.csv 0\n",
            "SJA.csv 0\n",
            "SUR.csv 0\n",
            "TAC.csv 0\n",
            "TAH.csv 2327\n",
            "TAX.csv 0\n",
            "TEC.csv 0\n",
            "TLA.csv 2140\n",
            "TLI.csv 2345\n",
            "TPN.csv 0\n",
            "UAX.csv 1919\n",
            "UIZ.csv 2307\n",
            "VAL.csv 0\n",
            "VIF.csv 2256\n",
            "XAL.csv 1313\n"
          ]
        }
      ],
      "source": [
        "traffic_dir = \"TRAFFIC_data\"\n",
        "if not os.path.exists(traffic_dir):\n",
        "    os.makedirs(traffic_dir)\n",
        "files = os.listdir(dir_raw_data)\n",
        "for filename in files:\n",
        "    file_path = os.path.join(dir_raw_data ,filename)\n",
        "    df = pd.read_csv(file_path)\n",
        "    #df = pd.read_csv(file_path, dtype={'date': 'str'})\n",
        "    #df = pd.read_csv(file_path, parse_dates=['date'], date_parser=lambda x: pd.to_datetime(x, format='%Y/%m/%d %H:%M'))\n",
        "\n",
        "    df['date'] = pd.to_datetime(df['date'], format='%Y/%m/%d %H:%M')\n",
        "    #df['date'] = df['date'].dt.strftime('%Y/%m/%d %H:%M:%S')\n",
        "    fecha_inicio = pd.Timestamp('2024-02-23')\n",
        "    df = df[df['date'] > fecha_inicio].copy()\n",
        "    new_name = os.path.join(traffic_dir, filename)\n",
        "    print(filename,len(df))\n",
        "    df.to_csv(new_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ACO.csv\n",
            "AJM.csv\n",
            "AJU.csv\n",
            "ARA.csv\n",
            "ATI.csv\n",
            "AZC.csv\n",
            "BJU.csv\n",
            "CAM.csv\n",
            "CCA.csv\n",
            "CES.csv\n",
            "CHO.csv\n",
            "COY.csv\n",
            "CUA.csv\n",
            "CUT.csv\n",
            "FAC.csv\n",
            "FAR.csv\n",
            "GAM.csv\n",
            "HGM.csv\n",
            "IMP.csv\n",
            "INN.csv\n",
            "IZT.csv\n",
            "LAG.csv\n",
            "LLA.csv\n",
            "LPR.csv\n",
            "MER.csv\n",
            "MGH.csv\n",
            "MON.csv\n",
            "MPA.csv\n",
            "NEZ.csv\n",
            "PED.csv\n",
            "PLA.csv\n",
            "SAC.csv\n",
            "SAG.csv\n",
            "SFE.csv\n",
            "SJA.csv\n",
            "SUR.csv\n",
            "TAC.csv\n",
            "TAH.csv\n",
            "TAX.csv\n",
            "TEC.csv\n",
            "TLA.csv\n",
            "TLI.csv\n",
            "TPN.csv\n",
            "UAX.csv\n",
            "UIZ.csv\n",
            "VAL.csv\n",
            "VIF.csv\n",
            "XAL.csv\n"
          ]
        }
      ],
      "source": [
        "stations = ['AJM', 'CUA', 'CUT', 'FAC', 'MER', 'NEZ', 'PED', 'SAC', 'UIZ', 'VIF']\n",
        "dir_traffic_preprocessed_data = \"TRAFFIC_data/dir_traffic_preprocessed_data\"\n",
        "dir = \"TRAFFIC_data\"\n",
        "if not os.path.exists(dir_traffic_preprocessed_data):\n",
        "    os.makedirs(dir_traffic_preprocessed_data)\n",
        "files = os.listdir(dir)\n",
        "for file in files:\n",
        "    if file.endswith(\".csv\"):\n",
        "        print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAFFIC_data\\ACO.csv\n",
            "TRAFFIC_data\\AJM.csv\n",
            "TRAFFIC_data\\AJU.csv\n",
            "TRAFFIC_data\\ARA.csv\n",
            "TRAFFIC_data\\ATI.csv\n",
            "TRAFFIC_data\\AZC.csv\n",
            "TRAFFIC_data\\BJU.csv\n",
            "TRAFFIC_data\\CAM.csv\n",
            "TRAFFIC_data\\CCA.csv\n",
            "TRAFFIC_data\\CES.csv\n",
            "TRAFFIC_data\\CHO.csv\n",
            "TRAFFIC_data\\COY.csv\n",
            "TRAFFIC_data\\CUA.csv\n",
            "TRAFFIC_data\\CUT.csv\n",
            "TRAFFIC_data\\FAC.csv\n",
            "TRAFFIC_data\\FAR.csv\n",
            "TRAFFIC_data\\GAM.csv\n",
            "TRAFFIC_data\\HGM.csv\n",
            "TRAFFIC_data\\IMP.csv\n",
            "TRAFFIC_data\\INN.csv\n",
            "TRAFFIC_data\\IZT.csv\n",
            "TRAFFIC_data\\LAG.csv\n",
            "TRAFFIC_data\\LLA.csv\n",
            "TRAFFIC_data\\LPR.csv\n",
            "TRAFFIC_data\\MER.csv\n",
            "TRAFFIC_data\\MGH.csv\n",
            "TRAFFIC_data\\MON.csv\n",
            "TRAFFIC_data\\MPA.csv\n",
            "TRAFFIC_data\\NEZ.csv\n",
            "TRAFFIC_data\\PED.csv\n",
            "TRAFFIC_data\\PLA.csv\n",
            "TRAFFIC_data\\SAC.csv\n",
            "TRAFFIC_data\\SAG.csv\n",
            "TRAFFIC_data\\SFE.csv\n",
            "TRAFFIC_data\\SJA.csv\n",
            "TRAFFIC_data\\SUR.csv\n",
            "TRAFFIC_data\\TAC.csv\n",
            "TRAFFIC_data\\TAH.csv\n",
            "TRAFFIC_data\\TAX.csv\n",
            "TRAFFIC_data\\TEC.csv\n",
            "TRAFFIC_data\\TLA.csv\n",
            "TRAFFIC_data\\TLI.csv\n",
            "TRAFFIC_data\\TPN.csv\n",
            "TRAFFIC_data\\UAX.csv\n",
            "TRAFFIC_data\\UIZ.csv\n",
            "TRAFFIC_data\\VAL.csv\n",
            "TRAFFIC_data\\VIF.csv\n",
            "TRAFFIC_data\\XAL.csv\n"
          ]
        }
      ],
      "source": [
        "stations = ['AJM', 'CUA', 'CUT', 'FAC', 'MER', 'NEZ', 'PED', 'SAC', 'UIZ', 'VIF']\n",
        "\n",
        "dir_traffic_preprocessed_data = \"TRAFFIC_data/dir_traffic_preprocessed_data\"\n",
        "dir = \"TRAFFIC_data\"\n",
        "if not os.path.exists(dir_traffic_preprocessed_data):\n",
        "    os.makedirs(dir_traffic_preprocessed_data)\n",
        "\n",
        "dir = 'TRAFFIC_data'  \n",
        "files = os.listdir(dir)\n",
        "\n",
        "info_datasets = []\n",
        "columnas = [\"file_name\", \"len_dataset\",\"%datosFaltantes\"]\n",
        "\n",
        "for file_name in files:\n",
        "    if file_name.endswith(\".csv\"):\n",
        "        file_path = os.path.join(dir,file_name)\n",
        "        print(file_path)\n",
        "        dataset = pd.read_csv(file_path)\n",
        "        if len(dataset) > 0:\n",
        "            dataset[['year', 'month', 'day']] = dataset['date'].str.split('-', expand=True)\n",
        "            dataset[\"hour\"] = dataset[\"day\"]\n",
        "            dataset[[\"day\", \"hour\"]] = dataset[\"day\"].str.split(' ', expand=True)\n",
        "            dataset[[\"hour\",\"minute\", \"second\"]] = dataset[\"hour\"].str.split(':', expand=True)\n",
        "\n",
        "            porcentaje_total_vacios = round(dataset.isna().mean().mean() * 100,2)\n",
        "            info_datasets.append([file_name, len(dataset), porcentaje_total_vacios])\n",
        "            \n",
        "            #dataset = dataset.dropna(axis=1, how='all')\n",
        "            df = dataset.copy()\n",
        "\n",
        "            # Borra por columnas, si toda la columna esta vacía (suma 0) entonces la borra completa\n",
        "            for i in dataset:\n",
        "                suma = dataset[i].sum()\n",
        "                if suma == 0:\n",
        "                    df.drop(columns=[i], inplace=True)\n",
        "\n",
        "            dataset = df\n",
        "            # Borra por fila, Drop rows which contain missing values.\n",
        "            dataset = dataset.dropna(axis=0)\n",
        "            df = dataset[[\"date\", \"year\", \"month\", \"day\", \"hour\", \"minute\"]].copy()\n",
        "            dataset = dataset.drop([\"date\", \"year\", \"month\", \"day\", \"hour\", \"minute\"], axis=1)\n",
        "            # Elimina aquellas columnas que tienen solo un valor único en todas sus filas.\n",
        "            for column in dataset.columns:\n",
        "                if dataset[column].nunique() == 1:\n",
        "                    dataset = dataset.drop(columns=[column], axis=1)\n",
        "\n",
        "            # Eliminación de las filas con valores negativos\n",
        "            dataset = dataset[(dataset >= 0).all(axis=1)]\n",
        "\n",
        "            # Cambio de unidades. Conversión de ppm a ppb\n",
        "            if \"CO\" in dataset.columns:\n",
        "                dataset[\"CO\"] = dataset[\"CO\"] * 1000\n",
        "\n",
        "            if len(dataset) > 0 and len(dataset.columns) > 0:\n",
        "                # Normalización\n",
        "                scaler = MinMaxScaler()\n",
        "                df_normalized = scaler.fit_transform(dataset)\n",
        "                dataset = pd.DataFrame(df_normalized, columns=dataset.columns)\n",
        "                df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "                dataset.insert(0, \"date\", df[\"date\"])\n",
        "                df = df.drop([\"date\"], axis=1)\n",
        "                dataset[[\"year\", \"month\", \"day\", \"hour\", \"minute\"]] = df    \n",
        "\n",
        "                name = os.path.join(dir_traffic_preprocessed_data, file_name)\n",
        "                dataset.to_csv(name, index=False)\n",
        "\n",
        "info_name = \"info_split_datasets_soloTrafico.csv\"\n",
        "info_datasets = pd.DataFrame(info_datasets, columns=columnas)\n",
        "info_datasets.to_csv(info_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AJM\n",
            "2024-02-23 01:00:00 2024-05-31 19:00:00 1097 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'PM25', 'RH', 'SO2', 'TMP',\n",
            "       'WDR', 'WSP'],\n",
            "      dtype='object')\n",
            "\n",
            "AJU\n",
            "2024-02-23 03:00:00 2024-05-31 11:00:00 1330 Index(['O3', 'PM25', 'RH', 'TMP', 'WDR', 'WSP'], dtype='object')\n",
            "\n",
            "ATI\n",
            "2024-02-23 01:00:00 2024-05-31 16:00:00 2068 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'SO2'], dtype='object')\n",
            "\n",
            "BJU\n",
            "2024-02-23 01:00:00 2024-05-31 16:00:00 1449 Index(['CO', 'NO2', 'O3', 'PM10', 'PM25', 'RH', 'SO2', 'TMP', 'WDR', 'WSP'], dtype='object')\n",
            "\n",
            "CAM\n",
            "2024-02-23 02:00:00 2024-05-24 15:00:00 1208 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'PM25', 'SO2'], dtype='object')\n",
            "\n",
            "CCA\n",
            "2024-02-23 02:00:00 2024-05-31 17:00:00 2083 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM25', 'SO2'], dtype='object')\n",
            "\n",
            "CHO\n",
            "2024-02-28 12:00:00 2024-05-22 11:00:00 56 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'SO2', 'WDR', 'WSP'], dtype='object')\n",
            "\n",
            "CUA\n",
            "2024-02-23 02:00:00 2024-03-14 09:00:00 422 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'RH', 'SO2', 'TMP', 'WDR',\n",
            "       'WSP'],\n",
            "      dtype='object')\n",
            "\n",
            "CUT\n",
            "2024-02-23 10:00:00 2024-05-31 23:00:00 361 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'RH', 'SO2', 'TMP', 'WDR',\n",
            "       'WSP'],\n",
            "      dtype='object')\n",
            "\n",
            "FAC\n",
            "2024-02-23 01:00:00 2024-05-30 20:00:00 1822 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'RH', 'SO2', 'TMP', 'WDR',\n",
            "       'WSP'],\n",
            "      dtype='object')\n",
            "\n",
            "FAR\n",
            "2024-02-23 02:00:00 2024-05-10 13:00:00 1339 Index(['CO', 'NO2', 'O3', 'PM25', 'RH', 'SO2', 'WDR', 'WSP'], dtype='object')\n",
            "\n",
            "GAM\n",
            "2024-02-23 02:00:00 2024-05-31 23:00:00 1922 Index(['NO2', 'O3', 'PM10', 'PM25', 'RH', 'TMP', 'WDR', 'WSP'], dtype='object')\n",
            "\n",
            "HGM\n",
            "2024-02-23 01:00:00 2024-05-31 20:00:00 1504 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'PM25', 'SO2'], dtype='object')\n",
            "\n",
            "INN\n",
            "2024-04-16 17:00:00 2024-04-30 00:00:00 283 Index(['CO', 'O3', 'PM10', 'PM25', 'RH', 'SO2', 'TMP', 'WDR', 'WSP'], dtype='object')\n",
            "\n",
            "IZT\n",
            "2024-04-24 00:00:00 2024-05-31 23:00:00 463 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'SO2'], dtype='object')\n",
            "\n",
            "LLA\n",
            "2024-02-23 01:00:00 2024-05-31 23:00:00 2286 Index(['O3'], dtype='object')\n",
            "\n",
            "LPR\n",
            "2024-02-23 01:00:00 2024-05-31 23:00:00 2239 Index(['CO', 'O3', 'SO2'], dtype='object')\n",
            "\n",
            "MER\n",
            "2024-02-23 01:00:00 2024-05-31 22:00:00 1669 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'PM25', 'RH', 'SO2', 'TMP',\n",
            "       'WDR', 'WSP'],\n",
            "      dtype='object')\n",
            "\n",
            "MGH\n",
            "2024-02-23 01:00:00 2024-05-31 23:00:00 2167 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'RH', 'SO2', 'WDR', 'WSP'], dtype='object')\n",
            "\n",
            "MON\n",
            "2024-02-23 01:00:00 2024-05-30 21:00:00 1542 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM25', 'RH', 'SO2', 'TMP', 'WDR',\n",
            "       'WSP'],\n",
            "      dtype='object')\n",
            "\n",
            "MPA\n",
            "2024-02-23 08:00:00 2024-03-18 10:00:00 154 Index(['CO', 'NO2', 'O3', 'PM10', 'PM25', 'RH', 'SO2', 'TMP', 'WDR', 'WSP'], dtype='object')\n",
            "\n",
            "NEZ\n",
            "2024-02-23 08:00:00 2024-05-31 18:00:00 632 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'PM25', 'RH', 'SO2', 'TMP',\n",
            "       'WDR', 'WSP'],\n",
            "      dtype='object')\n",
            "\n",
            "PED\n",
            "2024-02-23 01:00:00 2024-05-22 09:00:00 1674 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'PM25', 'RH', 'SO2', 'TMP',\n",
            "       'WDR', 'WSP'],\n",
            "      dtype='object')\n",
            "\n",
            "SAC\n",
            "2024-02-23 01:00:00 2024-05-29 11:00:00 1820 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM25', 'RH', 'SO2', 'TMP', 'WDR',\n",
            "       'WSP'],\n",
            "      dtype='object')\n",
            "\n",
            "SAG\n",
            "2024-02-23 02:00:00 2024-05-31 20:00:00 1188 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'PM25', 'RH', 'SO2', 'TMP',\n",
            "       'WDR', 'WSP'],\n",
            "      dtype='object')\n",
            "\n",
            "TAH\n",
            "2024-02-23 01:00:00 2024-03-15 16:00:00 262 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'RH', 'SO2', 'TMP', 'WDR',\n",
            "       'WSP'],\n",
            "      dtype='object')\n",
            "\n",
            "TLA\n",
            "2024-03-21 00:00:00 2024-05-31 23:00:00 745 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'PM25', 'SO2'], dtype='object')\n",
            "\n",
            "TLI\n",
            "2024-02-23 01:00:00 2024-05-31 21:00:00 1849 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'SO2'], dtype='object')\n",
            "\n",
            "UAX\n",
            "2024-05-25 12:00:00 2024-05-31 12:00:00 4 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM25', 'WDR', 'WSP'], dtype='object')\n",
            "\n",
            "UIZ\n",
            "2024-02-23 01:00:00 2024-05-29 06:00:00 1646 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'PM25', 'RH', 'SO2', 'TMP',\n",
            "       'WDR', 'WSP'],\n",
            "      dtype='object')\n",
            "\n",
            "VIF\n",
            "2024-05-04 06:00:00 2024-05-31 03:00:00 133 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'RH', 'SO2', 'TMP', 'WDR',\n",
            "       'WSP'],\n",
            "      dtype='object')\n",
            "\n",
            "XAL\n",
            "2024-02-23 01:00:00 2024-05-31 23:00:00 886 Index(['CO', 'NO', 'NOX', 'NO2', 'O3', 'SO2'], dtype='object')\n",
            "\n"
          ]
        }
      ],
      "source": [
        "columnas_especificas = ['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'PM25', 'RH', 'SO2', 'TMP', 'WDR', 'WSP']\n",
        "dir = \"TRAFFIC_data/dir_traffic_preprocessed_data\"\n",
        "files = os.listdir(dir)\n",
        "lista = []\n",
        "for file_name in files:\n",
        "    columnas_cont = []\n",
        "    print(file_name[:-4])\n",
        "    file_path = os.path.join(dir,file_name)\n",
        "    df = pd.read_csv(file_path)\n",
        "    valores_minimos = df.min()\n",
        "    valores_maximos = df.max()\n",
        "    df.drop(columns=[\"date\", \"year\", \"month\", \"day\", \"hour\", \"minute\"], inplace=True)\n",
        "    print(valores_minimos.date, valores_maximos.date, len(df), df.columns)\n",
        "    columnas_cont = [file_name[:-4], valores_minimos.date, valores_minimos.year, valores_maximos.date, valores_maximos.year, len(df)]\n",
        "    for columna in columnas_especificas:\n",
        "        if columna in df.columns:\n",
        "            columnas_cont.append(1)\n",
        "        else:\n",
        "            columnas_cont.append(0)\n",
        "    lista.append(columnas_cont)\n",
        "    print(\"\")\n",
        "\n",
        "info_name = \"data_preprocessed_datasets_solotrafico.csv\"\n",
        "lista_columnas = ['estacion', 'primer_registro','oldest_year', 'ultimo_registro', 'new_year', 'num_datos', 'CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'PM25', 'RH', 'SO2', 'TMP', 'WDR', 'WSP']\n",
        "info_datasets = pd.DataFrame(lista, columns=lista_columnas)\n",
        "info_datasets.to_csv(info_name, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Otra sección"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#trainfiles_route = os.path.join(os.pardir, 'preprocessing_airpollution_data/entrenamiento_datos_por_estacion_sin_NaN')\n",
        "#testfiles_route = '..\\\\preprocessing_airpollution_data/prueba_datos_por_estacion_sin_NaN'\n",
        "trainfiles_route = os.path.join(os.pardir, 'preprocessing_airpollution_data/entrenamiento_datos_por_estacion')\n",
        "testfiles_route = '..\\\\preprocessing_airpollution_data/prueba_datos_por_estacion'\n",
        "archivos = os.listdir(trainfiles_route)\n",
        "archivos = [\"PED.csv\"]\n",
        "# Acceder a cada archivo CSV\n",
        "for archivo in archivos:\n",
        "    train_dirfile = os.path.join(trainfiles_route, archivo)\n",
        "    station_name = archivo.replace(\".csv\",\"\")\n",
        "    print(station_name)\n",
        "    df_train = pd.read_csv(train_dirfile)\n",
        "    test_dirfile = os.path.join(testfiles_route, station_name+\".csv\")\n",
        "    df_test = pd.read_csv(test_dirfile)\n",
        "df = pd.concat([df_train, df_test], axis = 0)\n",
        "print(len(df), len(df_train), len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_nameTrain = \"PED_train_normalized.csv\"\n",
        "new_nameTest = \"PED_test_normalized.csv\"\n",
        "#train_procentage = round(len(df)*.8)\n",
        "#test_porcentage = round(len(df)*.05)\n",
        "#train_set = df[0:train_procentage]\n",
        "#val_set = df[train_procentage:train_procentage+validation_porcentage]\n",
        "#test_set = df[train_procentage+validation_porcentage:len(df)]\n",
        "df[\"date\"] = df[\"date\"].str.replace(\"-\", \"/\")\n",
        "df['date'] = pd.to_datetime(df['date'], format='%Y/%m/%d %H:%M:%S')\n",
        "fecha_limite = pd.Timestamp('2023-04-01')\n",
        "train_set = df[df['date'] < fecha_limite].copy()\n",
        "test_set = df[df['date'] > fecha_limite].copy()\n",
        "print(len(train_set),  len(test_set))\n",
        "print(len(train_set)+ len(test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set.to_csv(new_nameTrain, index=False)\n",
        "test_set.to_csv(new_nameTest, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los segmentamos en entrenamiento y prueba (se dejaron para prueba los datos de hace un año)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gAd2eJzXKFJ",
        "outputId": "47028060-e615-4754-a0b1-2778159de157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "datos_por_estacion_sin_NaN\\ACO.csv\n",
            "datos_por_estacion_sin_NaN\\AJM.csv\n",
            "datos_por_estacion_sin_NaN\\AJU.csv\n",
            "datos_por_estacion_sin_NaN\\ARA.csv\n",
            "datos_por_estacion_sin_NaN\\ATI.csv\n",
            "datos_por_estacion_sin_NaN\\AZC.csv\n",
            "datos_por_estacion_sin_NaN\\BJU.csv\n",
            "datos_por_estacion_sin_NaN\\CAM.csv\n",
            "datos_por_estacion_sin_NaN\\CCA.csv\n",
            "datos_por_estacion_sin_NaN\\CES.csv\n",
            "datos_por_estacion_sin_NaN\\CHO.csv\n",
            "datos_por_estacion_sin_NaN\\COY.csv\n",
            "datos_por_estacion_sin_NaN\\CUA.csv\n",
            "datos_por_estacion_sin_NaN\\CUT.csv\n",
            "datos_por_estacion_sin_NaN\\FAC.csv\n",
            "datos_por_estacion_sin_NaN\\FAR.csv\n",
            "datos_por_estacion_sin_NaN\\GAM.csv\n",
            "datos_por_estacion_sin_NaN\\HGM.csv\n",
            "datos_por_estacion_sin_NaN\\IMP.csv\n",
            "datos_por_estacion_sin_NaN\\INN.csv\n",
            "datos_por_estacion_sin_NaN\\IZT.csv\n",
            "datos_por_estacion_sin_NaN\\LAG.csv\n",
            "datos_por_estacion_sin_NaN\\LLA.csv\n",
            "datos_por_estacion_sin_NaN\\LPR.csv\n",
            "datos_por_estacion_sin_NaN\\MER.csv\n",
            "datos_por_estacion_sin_NaN\\MGH.csv\n",
            "datos_por_estacion_sin_NaN\\MON.csv\n",
            "datos_por_estacion_sin_NaN\\MPA.csv\n",
            "datos_por_estacion_sin_NaN\\NEZ.csv\n",
            "datos_por_estacion_sin_NaN\\PED.csv\n",
            "datos_por_estacion_sin_NaN\\PLA.csv\n",
            "datos_por_estacion_sin_NaN\\SAC.csv\n",
            "datos_por_estacion_sin_NaN\\SAG.csv\n",
            "datos_por_estacion_sin_NaN\\SFE.csv\n",
            "datos_por_estacion_sin_NaN\\SJA.csv\n",
            "datos_por_estacion_sin_NaN\\SUR.csv\n",
            "datos_por_estacion_sin_NaN\\TAC.csv\n",
            "datos_por_estacion_sin_NaN\\TAH.csv\n",
            "datos_por_estacion_sin_NaN\\TAX.csv\n",
            "datos_por_estacion_sin_NaN\\TEC.csv\n",
            "datos_por_estacion_sin_NaN\\TLA.csv\n",
            "datos_por_estacion_sin_NaN\\TLI.csv\n",
            "datos_por_estacion_sin_NaN\\TPN.csv\n",
            "datos_por_estacion_sin_NaN\\UAX.csv\n",
            "datos_por_estacion_sin_NaN\\UIZ.csv\n",
            "datos_por_estacion_sin_NaN\\VAL.csv\n",
            "datos_por_estacion_sin_NaN\\VIF.csv\n",
            "datos_por_estacion_sin_NaN\\XAL.csv\n"
          ]
        }
      ],
      "source": [
        "dir = \"datos_por_estacion_pre_processing\"\n",
        "new_dirTest = \"prueba_datos_por_estacion\"\n",
        "new_dirTrain = \"entrenamiento_datos_por_estacion\"\n",
        "\n",
        "if not os.path.exists(new_dirTest):\n",
        "    os.makedirs(new_dirTest)\n",
        "    \n",
        "if not os.path.exists(new_dirTrain):\n",
        "    os.makedirs(new_dirTrain)\n",
        "\n",
        "info_datasets = []\n",
        "columnas = [\"len_dataset_withoutNaN\",\"len_trainSet_withoutNaN\",\"len_testSet_withoutNaN\"]\n",
        "files = os.listdir(dir)\n",
        "for file_name in files:\n",
        "    file_path = os.path.join(dir,file_name)\n",
        "    print(file_path)\n",
        "    dataset = pd.read_csv(file_path)\n",
        "    if len(dataset)>0:\n",
        "        dataset[['year', 'month', 'day']] = dataset['date'].str.split('/', expand=True)\n",
        "        dataset[\"hour\"] = dataset[\"day\"]\n",
        "        dataset[[\"day\", \"hour\"]] = dataset[\"day\"].str.split(' ', expand=True)\n",
        "        dataset[[\"hour\",\"minute\"]] = dataset[\"hour\"].str.split(':', expand=True)\n",
        "        #Ver si se quita o no\n",
        "        #dataset['date'] = pd.to_datetime(dataset['date'], format='%Y/%m/%d %H:%M:%S')\n",
        "        dataset['date'] = pd.to_datetime(dataset['date'])\n",
        "        #dataset['date'] = pd.to_datetime(dataset[['year', 'month', 'day', 'hour','minute']])\n",
        "        #dataset['date'] = pd.to_datetime(dataset['date'])\n",
        "        fecha_limite = pd.Timestamp('2023-04-01')\n",
        "        train_set = dataset[dataset['date'] < fecha_limite].copy()\n",
        "        test_set = dataset[dataset['date'] > fecha_limite].copy()\n",
        "\n",
        "        new_nameTrain = os.path.join(new_dirTrain, file_name)\n",
        "        new_nameTest = os.path.join(new_dirTest, file_name)\n",
        "        train_set.to_csv(new_nameTrain, index=False)\n",
        "        test_set.to_csv(new_nameTest, index=False)\n",
        "        \n",
        "        info_datasets.append([len(dataset), len(train_set), len(test_set)])\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>len_dataset</th>\n",
              "      <th>%datosFaltantes</th>\n",
              "      <th>len_dataset_withoutNaN</th>\n",
              "      <th>len_trainSet_withoutNaN</th>\n",
              "      <th>len_testSet_withoutNaN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ACO.csv</td>\n",
              "      <td>193368</td>\n",
              "      <td>33.19</td>\n",
              "      <td>4588.0</td>\n",
              "      <td>4588.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AJM.csv</td>\n",
              "      <td>109937</td>\n",
              "      <td>25.45</td>\n",
              "      <td>36217.0</td>\n",
              "      <td>30376.0</td>\n",
              "      <td>5840.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AJU.csv</td>\n",
              "      <td>97827</td>\n",
              "      <td>43.39</td>\n",
              "      <td>5397.0</td>\n",
              "      <td>5397.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ARA.csv</td>\n",
              "      <td>41899</td>\n",
              "      <td>59.76</td>\n",
              "      <td>54796.0</td>\n",
              "      <td>49306.0</td>\n",
              "      <td>5490.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ATI.csv</td>\n",
              "      <td>245317</td>\n",
              "      <td>42.49</td>\n",
              "      <td>9448.0</td>\n",
              "      <td>9448.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AZC.csv</td>\n",
              "      <td>81505</td>\n",
              "      <td>44.70</td>\n",
              "      <td>65234.0</td>\n",
              "      <td>59859.0</td>\n",
              "      <td>5374.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>BJU.csv</td>\n",
              "      <td>122678</td>\n",
              "      <td>32.91</td>\n",
              "      <td>59257.0</td>\n",
              "      <td>52096.0</td>\n",
              "      <td>7160.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CAM.csv</td>\n",
              "      <td>218132</td>\n",
              "      <td>40.68</td>\n",
              "      <td>15613.0</td>\n",
              "      <td>13470.0</td>\n",
              "      <td>2143.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CCA.csv</td>\n",
              "      <td>134418</td>\n",
              "      <td>36.57</td>\n",
              "      <td>40219.0</td>\n",
              "      <td>40219.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CES.csv</td>\n",
              "      <td>85108</td>\n",
              "      <td>31.79</td>\n",
              "      <td>42704.0</td>\n",
              "      <td>37768.0</td>\n",
              "      <td>4936.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CHO.csv</td>\n",
              "      <td>200908</td>\n",
              "      <td>38.76</td>\n",
              "      <td>9856.0</td>\n",
              "      <td>6763.0</td>\n",
              "      <td>3092.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>COY.csv</td>\n",
              "      <td>144137</td>\n",
              "      <td>48.24</td>\n",
              "      <td>92959.0</td>\n",
              "      <td>86468.0</td>\n",
              "      <td>6491.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>CUA.csv</td>\n",
              "      <td>229608</td>\n",
              "      <td>32.69</td>\n",
              "      <td>36498.0</td>\n",
              "      <td>36465.0</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>CUT.csv</td>\n",
              "      <td>158321</td>\n",
              "      <td>30.33</td>\n",
              "      <td>98062.0</td>\n",
              "      <td>94239.0</td>\n",
              "      <td>3823.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>FAC.csv</td>\n",
              "      <td>270737</td>\n",
              "      <td>25.72</td>\n",
              "      <td>41127.0</td>\n",
              "      <td>41127.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>FAR.csv</td>\n",
              "      <td>71260</td>\n",
              "      <td>35.63</td>\n",
              "      <td>24910.0</td>\n",
              "      <td>24910.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>GAM.csv</td>\n",
              "      <td>110172</td>\n",
              "      <td>39.18</td>\n",
              "      <td>13538.0</td>\n",
              "      <td>13538.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>HGM.csv</td>\n",
              "      <td>157736</td>\n",
              "      <td>30.95</td>\n",
              "      <td>88000.0</td>\n",
              "      <td>81321.0</td>\n",
              "      <td>6678.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>IMP.csv</td>\n",
              "      <td>74286</td>\n",
              "      <td>58.81</td>\n",
              "      <td>23962.0</td>\n",
              "      <td>23962.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>INN.csv</td>\n",
              "      <td>108588</td>\n",
              "      <td>38.54</td>\n",
              "      <td>16685.0</td>\n",
              "      <td>11694.0</td>\n",
              "      <td>4990.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>IZT.csv</td>\n",
              "      <td>214234</td>\n",
              "      <td>36.63</td>\n",
              "      <td>13123.0</td>\n",
              "      <td>9410.0</td>\n",
              "      <td>3712.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>LAG.csv</td>\n",
              "      <td>83993</td>\n",
              "      <td>40.69</td>\n",
              "      <td>51209.0</td>\n",
              "      <td>46072.0</td>\n",
              "      <td>5137.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>LLA.csv</td>\n",
              "      <td>169806</td>\n",
              "      <td>50.28</td>\n",
              "      <td>16349.0</td>\n",
              "      <td>16349.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>LPR.csv</td>\n",
              "      <td>207427</td>\n",
              "      <td>52.99</td>\n",
              "      <td>6621.0</td>\n",
              "      <td>700.0</td>\n",
              "      <td>5921.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>MER.csv</td>\n",
              "      <td>257049</td>\n",
              "      <td>22.64</td>\n",
              "      <td>59923.0</td>\n",
              "      <td>55897.0</td>\n",
              "      <td>4026.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>MGH.csv</td>\n",
              "      <td>117181</td>\n",
              "      <td>26.87</td>\n",
              "      <td>36930.0</td>\n",
              "      <td>36930.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>MON.csv</td>\n",
              "      <td>222329</td>\n",
              "      <td>36.41</td>\n",
              "      <td>26331.0</td>\n",
              "      <td>26331.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>MPA.csv</td>\n",
              "      <td>94460</td>\n",
              "      <td>38.07</td>\n",
              "      <td>33220.0</td>\n",
              "      <td>33220.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>NEZ.csv</td>\n",
              "      <td>195809</td>\n",
              "      <td>32.99</td>\n",
              "      <td>24634.0</td>\n",
              "      <td>24634.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>PED.csv</td>\n",
              "      <td>255672</td>\n",
              "      <td>25.76</td>\n",
              "      <td>41367.0</td>\n",
              "      <td>38484.0</td>\n",
              "      <td>2883.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>PLA.csv</td>\n",
              "      <td>82556</td>\n",
              "      <td>28.97</td>\n",
              "      <td>29949.0</td>\n",
              "      <td>29949.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>SAC.csv</td>\n",
              "      <td>57084</td>\n",
              "      <td>29.37</td>\n",
              "      <td>14544.0</td>\n",
              "      <td>14544.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>SAG.csv</td>\n",
              "      <td>248463</td>\n",
              "      <td>25.40</td>\n",
              "      <td>83145.0</td>\n",
              "      <td>81063.0</td>\n",
              "      <td>2081.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>SFE.csv</td>\n",
              "      <td>134231</td>\n",
              "      <td>26.97</td>\n",
              "      <td>48430.0</td>\n",
              "      <td>44602.0</td>\n",
              "      <td>3828.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>SJA.csv</td>\n",
              "      <td>124413</td>\n",
              "      <td>45.88</td>\n",
              "      <td>15900.0</td>\n",
              "      <td>15900.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>SUR.csv</td>\n",
              "      <td>154987</td>\n",
              "      <td>30.09</td>\n",
              "      <td>42055.0</td>\n",
              "      <td>38746.0</td>\n",
              "      <td>3308.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>TAC.csv</td>\n",
              "      <td>76250</td>\n",
              "      <td>29.80</td>\n",
              "      <td>20200.0</td>\n",
              "      <td>15721.0</td>\n",
              "      <td>4479.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>TAH.csv</td>\n",
              "      <td>229229</td>\n",
              "      <td>34.06</td>\n",
              "      <td>56928.0</td>\n",
              "      <td>55291.0</td>\n",
              "      <td>1636.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>TAX.csv</td>\n",
              "      <td>67959</td>\n",
              "      <td>36.81</td>\n",
              "      <td>36374.0</td>\n",
              "      <td>36374.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>TEC.csv</td>\n",
              "      <td>14544</td>\n",
              "      <td>19.80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>TLA.csv</td>\n",
              "      <td>257192</td>\n",
              "      <td>24.06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>TLI.csv</td>\n",
              "      <td>227875</td>\n",
              "      <td>39.46</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>TPN.csv</td>\n",
              "      <td>125726</td>\n",
              "      <td>39.62</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>UAX.csv</td>\n",
              "      <td>152762</td>\n",
              "      <td>28.91</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>UIZ.csv</td>\n",
              "      <td>249299</td>\n",
              "      <td>31.87</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>VAL.csv</td>\n",
              "      <td>63297</td>\n",
              "      <td>57.81</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>VIF.csv</td>\n",
              "      <td>235974</td>\n",
              "      <td>27.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>XAL.csv</td>\n",
              "      <td>241091</td>\n",
              "      <td>28.17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   file_name  len_dataset  %datosFaltantes  len_dataset_withoutNaN  \\\n",
              "0    ACO.csv       193368            33.19                  4588.0   \n",
              "1    AJM.csv       109937            25.45                 36217.0   \n",
              "2    AJU.csv        97827            43.39                  5397.0   \n",
              "3    ARA.csv        41899            59.76                 54796.0   \n",
              "4    ATI.csv       245317            42.49                  9448.0   \n",
              "5    AZC.csv        81505            44.70                 65234.0   \n",
              "6    BJU.csv       122678            32.91                 59257.0   \n",
              "7    CAM.csv       218132            40.68                 15613.0   \n",
              "8    CCA.csv       134418            36.57                 40219.0   \n",
              "9    CES.csv        85108            31.79                 42704.0   \n",
              "10   CHO.csv       200908            38.76                  9856.0   \n",
              "11   COY.csv       144137            48.24                 92959.0   \n",
              "12   CUA.csv       229608            32.69                 36498.0   \n",
              "13   CUT.csv       158321            30.33                 98062.0   \n",
              "14   FAC.csv       270737            25.72                 41127.0   \n",
              "15   FAR.csv        71260            35.63                 24910.0   \n",
              "16   GAM.csv       110172            39.18                 13538.0   \n",
              "17   HGM.csv       157736            30.95                 88000.0   \n",
              "18   IMP.csv        74286            58.81                 23962.0   \n",
              "19   INN.csv       108588            38.54                 16685.0   \n",
              "20   IZT.csv       214234            36.63                 13123.0   \n",
              "21   LAG.csv        83993            40.69                 51209.0   \n",
              "22   LLA.csv       169806            50.28                 16349.0   \n",
              "23   LPR.csv       207427            52.99                  6621.0   \n",
              "24   MER.csv       257049            22.64                 59923.0   \n",
              "25   MGH.csv       117181            26.87                 36930.0   \n",
              "26   MON.csv       222329            36.41                 26331.0   \n",
              "27   MPA.csv        94460            38.07                 33220.0   \n",
              "28   NEZ.csv       195809            32.99                 24634.0   \n",
              "29   PED.csv       255672            25.76                 41367.0   \n",
              "30   PLA.csv        82556            28.97                 29949.0   \n",
              "31   SAC.csv        57084            29.37                 14544.0   \n",
              "32   SAG.csv       248463            25.40                 83145.0   \n",
              "33   SFE.csv       134231            26.97                 48430.0   \n",
              "34   SJA.csv       124413            45.88                 15900.0   \n",
              "35   SUR.csv       154987            30.09                 42055.0   \n",
              "36   TAC.csv        76250            29.80                 20200.0   \n",
              "37   TAH.csv       229229            34.06                 56928.0   \n",
              "38   TAX.csv        67959            36.81                 36374.0   \n",
              "39   TEC.csv        14544            19.80                     NaN   \n",
              "40   TLA.csv       257192            24.06                     NaN   \n",
              "41   TLI.csv       227875            39.46                     NaN   \n",
              "42   TPN.csv       125726            39.62                     NaN   \n",
              "43   UAX.csv       152762            28.91                     NaN   \n",
              "44   UIZ.csv       249299            31.87                     NaN   \n",
              "45   VAL.csv        63297            57.81                     NaN   \n",
              "46   VIF.csv       235974            27.50                     NaN   \n",
              "47   XAL.csv       241091            28.17                     NaN   \n",
              "\n",
              "    len_trainSet_withoutNaN  len_testSet_withoutNaN  \n",
              "0                    4588.0                     0.0  \n",
              "1                   30376.0                  5840.0  \n",
              "2                    5397.0                     0.0  \n",
              "3                   49306.0                  5490.0  \n",
              "4                    9448.0                     0.0  \n",
              "5                   59859.0                  5374.0  \n",
              "6                   52096.0                  7160.0  \n",
              "7                   13470.0                  2143.0  \n",
              "8                   40219.0                     0.0  \n",
              "9                   37768.0                  4936.0  \n",
              "10                   6763.0                  3092.0  \n",
              "11                  86468.0                  6491.0  \n",
              "12                  36465.0                    32.0  \n",
              "13                  94239.0                  3823.0  \n",
              "14                  41127.0                     0.0  \n",
              "15                  24910.0                     0.0  \n",
              "16                  13538.0                     0.0  \n",
              "17                  81321.0                  6678.0  \n",
              "18                  23962.0                     0.0  \n",
              "19                  11694.0                  4990.0  \n",
              "20                   9410.0                  3712.0  \n",
              "21                  46072.0                  5137.0  \n",
              "22                  16349.0                     0.0  \n",
              "23                    700.0                  5921.0  \n",
              "24                  55897.0                  4026.0  \n",
              "25                  36930.0                     0.0  \n",
              "26                  26331.0                     0.0  \n",
              "27                  33220.0                     0.0  \n",
              "28                  24634.0                     0.0  \n",
              "29                  38484.0                  2883.0  \n",
              "30                  29949.0                     0.0  \n",
              "31                  14544.0                     0.0  \n",
              "32                  81063.0                  2081.0  \n",
              "33                  44602.0                  3828.0  \n",
              "34                  15900.0                     0.0  \n",
              "35                  38746.0                  3308.0  \n",
              "36                  15721.0                  4479.0  \n",
              "37                  55291.0                  1636.0  \n",
              "38                  36374.0                     0.0  \n",
              "39                      NaN                     NaN  \n",
              "40                      NaN                     NaN  \n",
              "41                      NaN                     NaN  \n",
              "42                      NaN                     NaN  \n",
              "43                      NaN                     NaN  \n",
              "44                      NaN                     NaN  \n",
              "45                      NaN                     NaN  \n",
              "46                      NaN                     NaN  \n",
              "47                      NaN                     NaN  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "info_name = \"info_split_datasets.csv\"\n",
        "info_data = pd.read_csv(info_name)\n",
        "info_datasets = pd.DataFrame(info_datasets, columns=columnas)\n",
        "info_data = pd.concat([info_data,info_datasets], axis=1)\n",
        "info_datasets.to_csv(info_name, index=False)\n",
        "info_data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
