{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SuAkpPKsW9UQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nuevo_nombre_carpeta = 'all_data_2005xstation_15_05_2024'  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASeowmTGXT92"
      },
      "source": [
        "Primero unimos los nuevos datos a los datos ya guardados en su respectiva estación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Valores hasta 15 de mayo 2024\n",
        "AJM.csv AJM.csv\n",
        "108873 1064 109937\n",
        "BJU.csv BJU.csv\n",
        "121613 1065 122678\n",
        "CAM.csv CAM.csv\n",
        "217118 1014 218132\n",
        "CCA.csv CCA.csv\n",
        "133365 1053 134418\n",
        "CUA.csv CUA.csv\n",
        "228566 1042 229608\n",
        "GAM.csv GAM.csv\n",
        "109108 1064 110172\n",
        "MGH.csv MGH.csv\n",
        "116118 1063 117181\n",
        "NEZ.csv NEZ.csv\n",
        "194751 1058 195809\n",
        "PED.csv PED.csv\n",
        "254680 992 255672\n",
        "SAC.csv SAC.csv\n",
        "56018 1066 57084\n",
        "SAG.csv SAG.csv\n",
        "247532 931 248463\n",
        "SFE.csv SFE.csv\n",
        "134231 0 134231\n",
        "TAH.csv TAH.csv\n",
        "228177 1052 229229\n",
        "TLI.csv TLI.csv\n",
        "226817 1058 227875\n",
        "VIF.csv VIF.csv\n",
        "234964 1010 235974"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK24Q0OfXbtN",
        "outputId": "56efc8c5-e1b9-4b2a-bc6c-16a7ae000288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AJM.csv AJM.csv\n",
            "108873 1064 109937\n",
            "BJU.csv BJU.csv\n",
            "121613 1065 122678\n",
            "CAM.csv CAM.csv\n",
            "217118 1014 218132\n",
            "CCA.csv CCA.csv\n",
            "133365 1053 134418\n",
            "CUA.csv CUA.csv\n",
            "228566 1042 229608\n",
            "GAM.csv GAM.csv\n",
            "109108 1064 110172\n",
            "MGH.csv MGH.csv\n",
            "116118 1063 117181\n",
            "NEZ.csv NEZ.csv\n",
            "194751 1058 195809\n",
            "PED.csv PED.csv\n",
            "254680 992 255672\n",
            "SAC.csv SAC.csv\n",
            "56018 1066 57084\n",
            "SAG.csv SAG.csv\n",
            "247532 931 248463\n",
            "SFE.csv SFE.csv\n",
            "134231 0 134231\n",
            "TAH.csv TAH.csv\n",
            "228177 1052 229229\n",
            "TLI.csv TLI.csv\n",
            "226817 1058 227875\n",
            "VIF.csv VIF.csv\n",
            "234964 1010 235974\n"
          ]
        }
      ],
      "source": [
        "dir = \"all_data_2005xstation_31_03_2024\"\n",
        "dirNewData = \"datos_por_estacion\"\n",
        "filesPREV = os.listdir(dir)\n",
        "filesNEW = os.listdir(dirNewData)\n",
        "for file_name in filesPREV:\n",
        "  for file_nameNEW in filesNEW:\n",
        "    if file_name == file_nameNEW:\n",
        "      print(file_name, file_nameNEW)\n",
        "      file_pathPREV = os.path.join(dir,file_name)\n",
        "      datasetPREV = pd.read_csv(file_pathPREV)\n",
        "      file_pathNEWdata = os.path.join(dirNewData,file_name)\n",
        "      datasetNEWdata = pd.read_csv(file_pathNEWdata)\n",
        "      new_df = pd.concat([datasetPREV, datasetNEWdata])\n",
        "      new_df.to_csv(file_pathPREV, index=False)\n",
        "      print(len(datasetPREV), len(datasetNEWdata), len(new_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se renombra la carpeta con la fecha de los últimos datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Renombrar la carpeta\n",
        "os.rename(dir, nuevo_nombre_carpeta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTmIFPiiaolP"
      },
      "source": [
        "Luego los segmentamos en 80%, 15% y 5% para entrenamiento, prueba y validación respectivamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gAd2eJzXKFJ",
        "outputId": "47028060-e615-4754-a0b1-2778159de157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "entrenamiento datos por estacion\\AJM.csv 109937 87950 87950 80 16491 15 5496 5.0 25.45 25.77 27.25 15.01\n",
            "entrenamiento datos por estacion\\BJU.csv 122678 98142 98142 80 18402 15 6134 5.0 32.91 33.35 32.59 26.79\n",
            "entrenamiento datos por estacion\\CAM.csv 218132 174506 174506 80 32720 15 10906 5.0 40.68 41.91 36.39 33.7\n",
            "entrenamiento datos por estacion\\CCA.csv 134418 107534 107534 80 20163 15 6721 5.0 36.57 36.68 36.67 34.67\n",
            "entrenamiento datos por estacion\\CUA.csv 229608 183686 183686 80 34441 15 11481 5.0 32.69 33.71 29.79 25.12\n",
            "entrenamiento datos por estacion\\GAM.csv 110172 88138 88138 80 16526 15 5508 5.0 39.18 38.8 43.05 33.56\n",
            "entrenamiento datos por estacion\\MGH.csv 117181 93745 93745 80 17577 15 5859 5.0 26.87 25.98 31.83 26.3\n",
            "entrenamiento datos por estacion\\NEZ.csv 195809 156647 156647 80 29371 15 9791 5.0 32.99 34.12 26.69 33.68\n",
            "entrenamiento datos por estacion\\PED.csv 255672 204538 204538 80 38351 15 12783 5.0 25.76 26.22 25.17 20.17\n",
            "entrenamiento datos por estacion\\SAC.csv 57084 45667 45667 80 8563 15 2854 5.0 29.37 30.5 30.65 7.59\n",
            "entrenamiento datos por estacion\\SAG.csv 248463 198770 198770 80 37269 15 12424 5.0 25.4 25.1 27.2 24.79\n",
            "entrenamiento datos por estacion\\SFE.csv 134231 107385 107385 80 20135 15 6711 5.0 26.97 27.78 18.59 39.05\n",
            "entrenamiento datos por estacion\\TAH.csv 229229 183383 183383 80 34384 15 11462 5.0 34.06 35.57 28.05 27.8\n",
            "entrenamiento datos por estacion\\TLI.csv 227875 182300 182300 80 34181 15 11394 5.0 39.46 39.24 41.65 36.34\n",
            "entrenamiento datos por estacion\\VIF.csv 235974 188779 188779 80 35396 15 11799 5.0 27.5 27.1 28.22 31.81\n"
          ]
        }
      ],
      "source": [
        "new_dirTest = \"prueba_datos_por_estacion\"\n",
        "new_dirTrain = \"entrenamiento_datos_por_estacion\"\n",
        "new_dirVal = \"validacion_datos_por_estacion\"\n",
        "\n",
        "if not os.path.exists(new_dirTest):\n",
        "    os.makedirs(new_dirTest)\n",
        "    \n",
        "if not os.path.exists(new_dirTrain):\n",
        "    os.makedirs(new_dirTrain)\n",
        "    \n",
        "if not os.path.exists(new_dirVal):\n",
        "    os.makedirs(new_dirVal)\n",
        "\n",
        "info_datasets = []\n",
        "columnas = [\"file_name\", \"len_dataset\",\".8dataset\", \"len_trainSet\", \"train%\", \"len_testSet\", \"test%\", \"lenValSet\", \"val%\", \"%datosFaltantes\", \"%dastosFaltantesTrain\", \"%dastosFaltantesTest\", \"%dastosFaltantesVal\"]\n",
        "files = os.listdir(dir)\n",
        "for file_name in files:\n",
        "  file_path = os.path.join(dir,file_name)\n",
        "  dataset = pd.read_csv(file_path)\n",
        "  dataset[['year', 'month', 'day']] = dataset['date'].str.split('/', expand=True)\n",
        "  dataset[\"hour\"] = dataset[\"day\"]\n",
        "  dataset[[\"day\", \"hour\"]] = dataset[\"day\"].str.split(' ', expand=True)\n",
        "  dataset[[\"hour\",\"minute\"]] = dataset[\"hour\"].str.split(':', expand=True)\n",
        "  train_procentage = round(len(dataset)*.8)\n",
        "  test_porcentage = round(len(dataset)*.15)\n",
        "  validation_porcentage = round(len(dataset)*.05)\n",
        "  train_set = dataset[0:train_procentage]\n",
        "  test_set = dataset[train_procentage:train_procentage+test_porcentage]\n",
        "  val_set = dataset[train_procentage+test_porcentage:len(dataset)]\n",
        "  porcentaje_total_vacios = round(dataset.isna().mean().mean() * 100,2)\n",
        "  porc_vacios_train = round(train_set.isna().mean().mean() * 100,2)\n",
        "  porc_vacios_test = round(test_set.isna().mean().mean() * 100,2)\n",
        "  porc_vacios_val = round(val_set.isna().mean().mean() * 100,2)\n",
        "  info_datasets.append([file_name, len(dataset), round(len(dataset)*.8), len(train_set), round(len(train_set)*100/len(dataset)), len(test_set), round(len(test_set)*100/len(dataset)),len(val_set), round((len(val_set)*100/len(dataset)),2), porcentaje_total_vacios, porc_vacios_train, porc_vacios_test, porc_vacios_val])\n",
        "  new_nameTrain = os.path.join(new_dirTrain, file_name)\n",
        "  new_nameTest = os.path.join(new_dirTest, file_name)\n",
        "  new_nameVal = os.path.join(new_dirVal, file_name)\n",
        "  train_set.to_csv(new_nameTrain, index=False)\n",
        "  test_set.to_csv(new_nameTest, index=False)\n",
        "  val_set.to_csv(new_nameVal, index=False)\n",
        "  print(new_nameTrain, len(dataset), round(len(dataset)*.8), len(train_set), round(len(train_set)*100/len(dataset)), len(test_set), round(len(test_set)*100/len(dataset)),len(val_set), round((len(val_set)*100/len(dataset)),2), porcentaje_total_vacios, porc_vacios_train, porc_vacios_test, porc_vacios_val)\n",
        "\n",
        "info_name = \"info_split_datasets.csv\"\n",
        "info_datasets = pd.DataFrame(info_datasets, columns=columnas)\n",
        "info_datasets.to_csv(info_name, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se borran las carpetas que ya no se usarán"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "dir = \"datos_por_estacion\"\n",
        "shutil.rmtree(dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las carpetas con los datos x estación ya segmentados se encuentran en entrenamiento / prueba / y validación"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
