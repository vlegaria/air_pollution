{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es_ES.UTF-8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pickle\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import locale\n",
    "import pytz\n",
    "import os\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "#from utils.predictor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Cargar cliente mlfow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "client = MlflowClient()\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "tz_mexico = pytz.timezone('America/Mexico_City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 28-29: truncated \\UXXXXXXXX escape (3859357940.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 14\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 28-29: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "stations = [\"MER\", \"UIZ\"]\n",
    "for station in stations:\n",
    "    \"\"\"\n",
    "    # 15 min\n",
    "    dir = r\"C:\\Users\\valer\\Documents\\CIC\\doctorado\\Proyecto_Innovacion\\Datos\\air_traffic_\"\n",
    "    dir = dir+station+\".csv\"\n",
    "    df = pd.read_csv(dir)\n",
    "    df['traffic'] = df['traffic'].apply(lambda x: float(f\"{x:.2f}\"))\n",
    "    df[\"date\"] = df['date'].str.replace('/', '-')\n",
    "    df[\"date\"] = df[\"date\"].str[:-9]\n",
    "    # Traffic must be at the end\n",
    "    #col = df[\"traffic\"]\n",
    "    #df.insert(len(df), col.name, col)\n",
    "    \"\"\"\n",
    "    dir = dir[:-4]\n",
    "    dir = dir+\"_15m.csv\"\n",
    "    #df.to_csv(dir, index=False)\n",
    "\n",
    "    # prom\n",
    "    df = pd.read_csv(dir)\n",
    "    #Si son negativos o vacios cambiarlos a nan\n",
    "    for ind in range(df.shape[0]):\n",
    "        for dato in df.columns:\n",
    "            if(dato in [\"CO\", \"NO\",  \"NOX\",\"NO2\", \"O3\", \"PM10\", \"PM25\", \"RH\", \"SO2\", \"TMP\", \"WDR\", \"WSP\", \"traffic\"]):\n",
    "                if(df.loc[ind, dato] < 0):\n",
    "                    df.loc[ind, dato] = np.nan\n",
    "                    \n",
    "                if(df.loc[ind, dato] == \"\"):\n",
    "                    df.loc[ind, dato] = np.nan\n",
    "\n",
    "    dir = dir[:-4]\n",
    "    dir = dir+\"_prom_hr.csv\"\n",
    "    df.to_csv(dir, index=False)\n",
    "\n",
    "    \n",
    "    df = pd.read_csv(dir)\n",
    "    nuevoScaler = MinMaxScaler()\n",
    "    #Obtenemos los nuevos escalers\n",
    "    nuevoScaler.fit(df[[\"CO\", \"NO\", \"NOX\", \"NO2\", \"O3\", \"PM10\", \"PM25\", \"RH\", \"SO2\", \"TMP\", \"WDR\", \"WSP\", \"month\", \"hour\"]])\n",
    "    df_norm_data_escalada = df.copy()\n",
    "    #Obtener los nuevos valores escalados\n",
    "    df_norm_data_escalada[[\"CO\", \"NO\", \"NOX\", \"NO2\", \"O3\", \"PM10\", \"PM25\", \"RH\", \"SO2\", \"TMP\", \"WDR\", \"WSP\", \"month\", \"hour\"]] = nuevoScaler.transform(df[[\"CO\", \"NO\", \"NOX\", \"NO2\", \"O3\", \"PM10\", \"PM25\", \"RH\", \"SO2\", \"TMP\", \"WDR\", \"WSP\", \"month\", \"hour\"]])\n",
    "    #scaler_dir = dir[:-8]+'scaler.pkl'\n",
    "    scaler_dir = f\"C:/Users/valer/Documents/CIC/doctorado/Proyecto_Innovacion/Datos/{station}_scaler.pkl\"\n",
    "    pickle.dump(nuevoScaler, open(scaler_dir, \"wb\"))\n",
    "    dir2 = r\"C:\\Users\\valer\\Documents\\CIC\\doctorado\\Proyecto_Innovacion\\Datos\\air_traffic_MER_norm.csv\"\n",
    "    df_norm_data_escalada = df_norm_data_escalada.rename(columns={'minutes': 'minute'})\n",
    "    df_norm_data_escalada[['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'PM25', 'RH', 'SO2','TMP', 'WDR', 'WSP']] = df_norm_data_escalada[['CO', 'NO', 'NOX', 'NO2', 'O3', 'PM10', 'PM25', 'RH', 'SO2','TMP', 'WDR', 'WSP']].round(12)\n",
    "    df_norm_data_escalada = df_norm_data_escalada.where(pd.notnull(df_norm_data_escalada), \"nan\")\n",
    "    df_norm_data_escalada.to_csv(dir2, index=False)\n",
    "    #\"\"\"\n",
    "    dir = r\"C:\\Users\\valer\\Documents\\CIC\\doctorado\\Proyecto_Innovacion\\Datos\\air_and_traffic_\"\n",
    "    dir = dir+station+\"_prom.csv\"\n",
    "    df = pd.read_csv(dir)\n",
    "    df = df.where(pd.notnull(df), \"nan\")\n",
    "    #df= df.rename(columns={'minutes': 'minute'})\n",
    "    df.to_csv(dir, index=False)\n",
    "    dir = r\"C:\\Users\\valer\\Documents\\CIC\\doctorado\\Proyecto_Innovacion\\Datos\\air_and_traffic_\"\n",
    "    dir = dir+station+\"_15m.csv\"\n",
    "    df = pd.read_csv(dir)\n",
    "    df = df.where(pd.notnull(df), \"nan\")\n",
    "    #df= df.rename(columns={'minutes': 'minute'})\n",
    "    df.to_csv(dir, index=False)\n",
    "    #\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = r\"C:\\Users\\valer\\Documents\\CIC\\doctorado\\Proyecto_Innovacion\\Datos\\air_traffic_UIZ\"\n",
    "dir = dir+\"_prom.csv\"\n",
    "#df.to_csv(dir, index=False)\n",
    "station = \"UIZ\"\n",
    "df = pd.read_csv(dir)\n",
    "nuevoScaler = MinMaxScaler()\n",
    "#Obtenemos los nuevos escalers\n",
    "nuevoScaler.fit(df[[\"CO\", \"NO\", \"NOX\", \"NO2\", \"O3\", \"PM10\", \"PM25\", \"RH\", \"SO2\", \"TMP\", \"WDR\", \"WSP\"]])\n",
    "df_norm_data_escalada = df.copy()\n",
    "#Obtener los nuevos valores escalados\n",
    "df_norm_data_escalada[[\"CO\", \"NO\", \"NOX\", \"NO2\", \"O3\", \"PM10\", \"PM25\", \"RH\", \"SO2\", \"TMP\", \"WDR\", \"WSP\"]] = nuevoScaler.transform(df[[\"CO\", \"NO\", \"NOX\", \"NO2\", \"O3\", \"PM10\", \"PM25\", \"RH\", \"SO2\", \"TMP\", \"WDR\", \"WSP\"]])\n",
    "#scaler_dir = dir[:-8]+'scaler.pkl'\n",
    "scaler_dir = f\"C:/Users/valer/Documents/CIC/doctorado/Proyecto_Innovacion/Datos/{station}_scaler.pkl\"\n",
    "pickle.dump(nuevoScaler, open(scaler_dir, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"O3-\"+str(station.lower())+\"_24hr_forecast_model\"\n",
    "best_model_alias = \"champion\"\n",
    "\n",
    "best_model_info = client.get_model_version_by_alias(model_name, best_model_alias)\n",
    "best_model_run_id = best_model_info.run_id\n",
    "\n",
    "scaler_dir = 'artifacts/'+station.upper()+'_scaler.pkl'\n",
    "local_path = mlflow.artifacts.download_artifacts(run_id=best_model_run_id, artifact_path=scaler_dir)\n",
    "\n",
    "#Subir a modelo 24hr\n",
    "with mlflow.start_run(run_id=best_model_run_id) as run:\n",
    "    mlflow.log_artifact(f'ML/Scalers/{station}_scaler.pkl', artifact_path=\"artifacts\")\n",
    "\n",
    "#Subir a modelo 1hr\n",
    "model_name = \"O3-\"+str(station.lower())+\"_1hr_forecast_model\"\n",
    "best_model_alias = \"champion\"\n",
    "\n",
    "best_model_info = client.get_model_version_by_alias(model_name, best_model_alias)\n",
    "best_model_run_id = best_model_info.run_id\n",
    "\n",
    "with mlflow.start_run(run_id=best_model_run_id) as run:\n",
    "    mlflow.log_artifact(f'ML/Scalers/{station}_scaler.pkl', artifact_path=\"artifacts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils prediction\n",
    "    df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils request_data_15m\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "tz_mexico = pytz.timezone('America/Mexico_City')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conocenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{% extends 'core/base.html' %}\n",
    "{% block title %}Conocenos {% endblock %}\n",
    "\n",
    "{%block background%}{%load static%}{%static 'core/img/portfolio-bg.jpg'%}{%endblock%}\n",
    "\n",
    "{% block content %}\n",
    "<div class=\"col-lg-3 col-md-4 offset-lg-1\">\n",
    "  <img class=\"img-fluid avatar\" src=\"{%static 'core/img/AnaSaldaña.jpg' %}\" alt=\"\">\n",
    "</div>\n",
    "<div class=\"col-lg-7 col-md-8\" style=\"text-align: justify; color: black;\">\n",
    "  <h2 class=\"section-heading\" style=\"color: black; font-size: 24px !important;\">Ana M. Magdalena Saldaña Pérez</h2>\n",
    "  <h4 class=\"section-heading\" style=\"color: black; font-size: 18px !important;\">Académico responsable.</h4>    \n",
    "  <p style=\"color: black;\">Adscrita al Laboratorio de Procesamiento Inteligente de Información Geoespacial</p>\n",
    "  <p><a href=https://www.cic.ipn.mx/index.php/ana-maria-magdalena-saldana>Directorio CIC</a></p>\n",
    "</div>\n",
    "  <div class=\"col-lg-3 col-md-4 offset-lg-1\">\n",
    "    <img class=\"img-fluid avatar\" src=\"{%static 'core/img/valeria.jpg' %}\" alt=\"\">\n",
    "  </div>\n",
    "  <div class=\"col-lg-7 col-md-8\" style=\"text-align: justify; color: black;\">\n",
    "    <h2 class=\"section-heading\" style=\"color: black; font-size: 24px !important;\">Valeria Legaria</h2>\n",
    "    <p style=\"color: black;\">Estudiante de doctorado en Ciencias de la Computación, en el Centro de Investigación en Computación del Instituto Politécnico Nacional con interés por el medio ambiente y la inteligencia artificial.</p>\n",
    "    <p><a href=https://www.linkedin.com/in/valeria-legaria>LinkedIn</a></p>\n",
    "    <p><a href=https://github.com/vlegaria>Github</a></p>\n",
    "  </div>\n",
    "  <div class=\"row\">\n",
    "    <div class=\"col-lg-3 col-md-4 offset-lg-1\">\n",
    "      <img class=\"img-fluid avatar\" src=\"{%static 'core/img/francisco.jpg' %}\" alt=\"\">\n",
    "    </div>\n",
    "    <div class=\"col-lg-7 col-md-8\" style=\"text-align: justify; color: black;\">\n",
    "      <h2 class=\"section-heading\" style=\"color: black; font-size: 24px !important;\">Francisco Ramírez</h2>\n",
    "      <p style=\"color: black;\">Estudiante de Ingeniería Mecatrónica, la Unidad Profesional Interdisciplinaria en Ingeniería y Tecnologías Avanzadas (UPIITA) del Instituto Politécnico Nacional. Con habilidades en programación y electrónica.</p>\n",
    "      <p><a href=https://www.linkedin.com/in/francisco-ramirez-leon-203a13161>LinkedIn</a></p>\n",
    "      <p><a href=https://github.com/FrankXav>Github</a></p>\n",
    "    </div>\n",
    "  </div>\n",
    "  \n",
    "  <div class=\"col-lg-3 col-md-4 offset-lg-1  \">\n",
    "    <img class=\"img-fluid avatar\" src=\"{%static 'core/img/RafaelRojas.jpg' %}\" alt=\"\">\n",
    "  </div>\n",
    "  <div class=\"col-lg-7 col-md-8\" style=\"text-align: justify; color: black;\">\n",
    "    <h2 class=\"section-heading\" style=\"color: black; font-size: 24px !important;\">Rafael Rojas</h2>\n",
    "    <p style=\"color: black;\">Estudiante de Ing. Mecatrónica con amplia experiencia en el ámbito empresarial y apasionado por las ciencias computacionales, actualmente se desarrolla en el campo del ML y la Inteligencia Artificial</p>\n",
    "    <p><a href=https://www.linkedin.com/in/rafael-y-rojas-nieves-839881166>LinkedIn</a></p>\n",
    "    <p><a href=https://github.com/JFRo57/Portafolio>Github</a></p>\n",
    "  </div>\n",
    "  <div class=\"row\">\n",
    "    <div class=\"col-lg-3 col-md-4 offset-lg-1\">\n",
    "      <img class=\"img-fluid avatar\" src=\"{%static 'core/img/Yoqsan.jpeg' %}\" alt=\"\">\n",
    "    </div>\n",
    "  <div class=\"col-lg-7 col-md-8\" style=\"text-align: justify; color: black;\">\n",
    "  <h2 class=\"section-heading\" style=\"color: black; font-size: 24px !important;\">Yoqsan Angeles</h2>\n",
    "    <p style=\"color: black;\">Estudiante de doctorado en Ciencias de la Computación en el Instituto Politécnico Nacional de México, con trabajos en en desarrollo de algoritmos de optimización bioinspirados así como en el uso de redes neuronales aplicados en áreas como clasificación de patrones y robótica.</p>\n",
    "    <p><a href=https://www.linkedin.com/in/yoqsan-angeles-ba8769244>LinkedIn</a></p>\n",
    "  </div>\n",
    "  \n",
    "\n",
    "{% endblock %}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import locale\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pytz\n",
    "from utils.predictor import *\n",
    "\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "tz_mexico = pytz.timezone('America/Mexico_City')\n",
    "\n",
    "#Cargar cliente mlfow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ModelVersion: aliases=['champion'], creation_timestamp=1738086504124, current_stage='None', description='', last_updated_timestamp=1738086504124, name='O3-mer_24hr_forecast_model', run_id='9ea9f70e7d9142f29645b791bf5f848b', run_link='', source=('mlflow-artifacts:/171761569910041749/9ea9f70e7d9142f29645b791bf5f848b/artifacts/mer '\n",
      " 'station model for O3-24hr forecasting'), status='READY', status_message='', tags={'historicalData': '24'}, user_id='', version='1'>\n",
      "9ea9f70e7d9142f29645b791bf5f848b\n",
      "artifacts/MER_scaler_O3.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d8599e64fd4971a3d547c416ea3491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m local_path \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39martifacts\u001b[38;5;241m.\u001b[39mdownload_artifacts(run_id\u001b[38;5;241m=\u001b[39mbest_model_run_id, artifact_path\u001b[38;5;241m=\u001b[39mscaler_dir)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(local_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m---> 14\u001b[0m     scaler \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "station = \"mer\"\n",
    "model_name = \"O3-\"+str(station.lower())+\"_24hr_forecast_model\"\n",
    "best_model_alias = \"champion\"\n",
    "\n",
    "best_model_info = client.get_model_version_by_alias(model_name, best_model_alias)\n",
    "print(best_model_info)\n",
    "best_model_run_id = best_model_info.run_id\n",
    "print(best_model_run_id)\n",
    "scaler_dir = 'artifacts/'+station.upper()+'_scaler_O3.pkl'\n",
    "print(scaler_dir)\n",
    "local_path = mlflow.artifacts.download_artifacts(run_id=best_model_run_id, artifact_path=scaler_dir)\n",
    "\n",
    "with open(local_path, \"rb\") as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m station \u001b[38;5;129;01min\u001b[39;00m stations2forecast:\n\u001b[0;32m     62\u001b[0m     dataofDay \u001b[38;5;241m=\u001b[39m df_datos\u001b[38;5;241m.\u001b[39mloc[df_datos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFecha\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m dateData, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHora\u001b[39m\u001b[38;5;124m\"\u001b[39m,station]]\n\u001b[1;32m---> 64\u001b[0m     dato \u001b[38;5;241m=\u001b[39m dataofDay\u001b[38;5;241m.\u001b[39mloc[dataofDay[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHora\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m hour, station]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(dato \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(dato) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "import locale\n",
    "import pytz\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "tz_mexico = pytz.timezone('America/Mexico_City')\n",
    "stations2forecast = [\"MER\", \"UIZ\"]\n",
    "if True:\n",
    "    NOX = None\n",
    "    datetime_now = datetime.now(tz_mexico)\n",
    "    year = str(datetime_now.year)\n",
    "    date_df = datetime_now.strftime('%Y-%m-%d')\n",
    "    year = str(datetime_now.year)\n",
    "    month = str(datetime_now.month)\n",
    "    day = str(datetime_now.day)\n",
    "    hour = str(datetime_now.hour)\n",
    "    minute= str(datetime_now.minute)\n",
    "\n",
    "    #Preparar datos para buscar tabla\n",
    "    dayText = f'0{day}' if len(str(day)) == 1 else str(day)\n",
    "    monthText = f'0{month}' if len(str(month))  == 1 else str(month)\n",
    "    dateData = f'{dayText}-{monthText}-{year}'\n",
    "    \n",
    "    claveCont = ['co','no','nox','no2','o3','pm10','pm2','rh','so2','tmp','wdr','wsp']\n",
    "\n",
    "    #Crear dataframe vacio por estacion\n",
    "\n",
    "    contEstacion = pd.DataFrame(columns=[\"station\",\"date\", \"CO\", \"NO\", \"NOX\",\"NO2\", \"O3\", \"PM10\", \"PM25\", \"RH\", \"SO2\", \"TMP\", \"WDR\", \"WSP\", \"year\", \"month\", \"day\", \"hour\", \"minutes\", \"traffic\"])\n",
    "\n",
    "    for station in stations2forecast:\n",
    "        contEstacion = pd.concat([contEstacion, pd.DataFrame({\"station\":station,\n",
    "                                                \"date\":datetime_now,\n",
    "                                                \"year\":year,\n",
    "                                                \"month\":month,\n",
    "                                                \"day\":day,\n",
    "                                                \"hour\":hour,\n",
    "                                                \"minutes\":\"0\"}, index=[0])], ignore_index=True)\n",
    "\n",
    "    #print(contEstacion.head())\n",
    "\n",
    "    for cont in claveCont:\n",
    "        urlGob = f\"http://www.aire.cdmx.gob.mx/estadisticas-consultas/concentraciones/respuesta.php?qtipo=HORARIOS&parametro={cont}&anio={year}&qmes={month}\"\n",
    "        \n",
    "        #print(urlGob)\n",
    "        df_consulta = pd.read_html(urlGob, encoding='windows-1252')\n",
    "\n",
    "        df_datos = df_consulta[0]\n",
    "\n",
    "        df_datos.columns = df_datos.iloc[1]\n",
    "\n",
    "        df_datos = df_datos.drop([0,1])\n",
    "\n",
    "        #print(df_datos.head())\n",
    "\n",
    "        #Nombre de la culmna del contaminante en el dataframe de estaciones\n",
    "        if(cont == \"pm2\"):\n",
    "            colEstation = \"PM25\"\n",
    "        else: \n",
    "            colEstation = cont.upper()\n",
    "\n",
    "\n",
    "        for station in stations2forecast:\n",
    "            dataofDay = df_datos.loc[df_datos['Fecha'] == dateData, [\"Hora\",station]]\n",
    "\n",
    "            dato = dataofDay.loc[dataofDay['Hora'] == hour, station].values[0]\n",
    "\n",
    "            if(dato != \"nr\"):\n",
    "                if float(dato) >= 0:\n",
    "                    contEstacion.loc[contEstacion['station'] == station, colEstation] = dato\n",
    "                else: \n",
    "                    contEstacion.loc[contEstacion['station'] == station, colEstation] = np.nan\n",
    "            else: \n",
    "                contEstacion.loc[contEstacion['station'] == station, colEstation] = np.nan\n",
    "    print(\"Datos gob\")\n",
    "    #print(contEstacion.tail())\n",
    "    #\"CO\", \"NO\", \"NOX\",\"NO2\", \"O3\", \"PM10\", \"PM25\", \"RH\", \"SO2\", \"TMP\", \"WDR\", \"WSP\", \"year\", \"month\", \"day\", \"hour\", \"minutes\", \"traffic\"])\n",
    "    \n",
    "    #df['traffic'] = df['traffic'].apply(lambda x: float(f\"{x:.2f}\"))\n",
    "    #\"\"\"\n",
    "    CO =contEstacion.loc[contEstacion['station'] == station,\"CO\"].values[0]\n",
    "    NO = contEstacion.loc[contEstacion['station'] == station,\"NO\"].values[0]\n",
    "    NOX = contEstacion.loc[contEstacion['station'] == station,\"NOX\"].values[0]\n",
    "    NO2= contEstacion.loc[contEstacion['station'] == station,\"NO2\"].values[0]\n",
    "    O3= contEstacion.loc[contEstacion['station'] == station,\"O3\"].values[0]\n",
    "    PM10 =contEstacion.loc[contEstacion['station'] == station,\"PM10\"].values[0]\n",
    "    PM25 = contEstacion.loc[contEstacion['station'] == station,\"PM25\"].values[0]\n",
    "    RH = contEstacion.loc[contEstacion['station'] == station,\"RH\"].values[0]\n",
    "    SO2= contEstacion.loc[contEstacion['station'] == station,\"SO2\"].values[0]\n",
    "    TMP = contEstacion.loc[contEstacion['station'] == station,\"TMP\"].values[0]\n",
    "    WDR = contEstacion.loc[contEstacion['station'] == station,\"WDR\"].values[0]\n",
    "    WSP= contEstacion.loc[contEstacion['station'] == station,\"WSP\"].values[0]\n",
    "    print(CO, NO, NOX,NO2, O3, PM10, PM25, RH, SO2, TMP, WDR, WSP)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacio\n"
     ]
    }
   ],
   "source": [
    "if len(dataofDay.loc[dataofDay['Hora'] == hour, station]) == 0:\n",
    "    print(\"vacio\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "co MER\n",
      "1   Hora   MER\n",
      "674    1    nr\n",
      "675    2    nr\n",
      "676    3    nr\n",
      "677    4  0.72\n",
      "678    5  0.62\n",
      "679    6  0.82\n",
      "680    7  1.36\n",
      "681    8  2.46\n",
      "682    9  2.00\n",
      "683   10  1.22\n",
      "684   11  0.92\n",
      "685   12  0.79\n",
      "686   13    nr\n",
      "687   14  0.61\n",
      "co UIZ\n",
      "1   Hora   UIZ\n",
      "674    1    nr\n",
      "675    2    nr\n",
      "676    3    nr\n",
      "677    4  0.60\n",
      "678    5  0.56\n",
      "679    6  0.73\n",
      "680    7  1.24\n",
      "681    8  1.64\n",
      "682    9  2.48\n",
      "683   10  1.60\n",
      "684   11  1.76\n",
      "685   12  1.05\n",
      "686   13  0.81\n",
      "687   14  0.48\n",
      "no MER\n",
      "1   Hora  MER\n",
      "674    1   nr\n",
      "675    2   nr\n",
      "676    3   nr\n",
      "677    4    8\n",
      "678    5   10\n",
      "679    6   21\n",
      "680    7   67\n",
      "681    8  100\n",
      "682    9   93\n",
      "683   10   32\n",
      "684   11   13\n",
      "685   12   11\n",
      "686   13   nr\n",
      "687   14    4\n",
      "no UIZ\n",
      "1   Hora  UIZ\n",
      "674    1   nr\n",
      "675    2   nr\n",
      "676    3   nr\n",
      "677    4    2\n",
      "678    5    1\n",
      "679    6    3\n",
      "680    7   21\n",
      "681    8   58\n",
      "682    9  136\n",
      "683   10   39\n",
      "684   11   33\n",
      "685   12   12\n",
      "686   13    5\n",
      "687   14    2\n",
      "nox MER\n",
      "1   Hora  MER\n",
      "674    1   nr\n",
      "675    2   nr\n",
      "676    3   nr\n",
      "677    4   48\n",
      "678    5   50\n",
      "679    6   64\n",
      "680    7  114\n",
      "681    8  149\n",
      "682    9  147\n",
      "683   10   81\n",
      "684   11   53\n",
      "685   12   51\n",
      "686   13   nr\n",
      "687   14   31\n",
      "nox UIZ\n",
      "1   Hora  UIZ\n",
      "674    1   nr\n",
      "675    2   nr\n",
      "676    3   nr\n",
      "677    4   27\n",
      "678    5   25\n",
      "679    6   39\n",
      "680    7   67\n",
      "681    8  106\n",
      "682    9  191\n",
      "683   10   98\n",
      "684   11  112\n",
      "685   12   59\n",
      "686   13   37\n",
      "687   14   16\n",
      "no2 MER\n",
      "1   Hora MER\n",
      "674    1  nr\n",
      "675    2  nr\n",
      "676    3  nr\n",
      "677    4  39\n",
      "678    5  40\n",
      "679    6  43\n",
      "680    7  47\n",
      "681    8  49\n",
      "682    9  54\n",
      "683   10  49\n",
      "684   11  40\n",
      "685   12  40\n",
      "686   13  nr\n",
      "687   14  27\n",
      "no2 UIZ\n",
      "1   Hora UIZ\n",
      "674    1  nr\n",
      "675    2  nr\n",
      "676    3  nr\n",
      "677    4  26\n",
      "678    5  25\n",
      "679    6  36\n",
      "680    7  46\n",
      "681    8  49\n",
      "682    9  55\n",
      "683   10  59\n",
      "684   11  80\n",
      "685   12  47\n",
      "686   13  32\n",
      "687   14  15\n",
      "o3 MER\n",
      "1   Hora MER\n",
      "674    1  nr\n",
      "675    2  nr\n",
      "676    3  nr\n",
      "677    4  12\n",
      "678    5   8\n",
      "679    6   4\n",
      "680    7   1\n",
      "681    8   2\n",
      "682    9   4\n",
      "683   10  16\n",
      "684   11  35\n",
      "685   12  47\n",
      "686   13  nr\n",
      "687   14  73\n",
      "o3 UIZ\n",
      "1   Hora UIZ\n",
      "674    1  nr\n",
      "675    2  nr\n",
      "676    3  nr\n",
      "677    4  24\n",
      "678    5  25\n",
      "679    6  14\n",
      "680    7   5\n",
      "681    8   6\n",
      "682    9  11\n",
      "683   10  20\n",
      "684   11  32\n",
      "685   12  56\n",
      "686   13  75\n",
      "687   14  77\n",
      "pm10 MER\n",
      "1   Hora MER\n",
      "674    1  48\n",
      "675    2  49\n",
      "676    3  38\n",
      "677    4  50\n",
      "678    5  38\n",
      "679    6  35\n",
      "680    7  36\n",
      "681    8  43\n",
      "682    9  48\n",
      "683   10  51\n",
      "684   11  38\n",
      "685   12  55\n",
      "686   13  nr\n",
      "687   14  13\n",
      "pm10 UIZ\n",
      "1   Hora UIZ\n",
      "674    1  53\n",
      "675    2  47\n",
      "676    3  40\n",
      "677    4  44\n",
      "678    5  34\n",
      "679    6  33\n",
      "680    7  31\n",
      "681    8  37\n",
      "682    9  41\n",
      "683   10  71\n",
      "684   11  67\n",
      "685   12  72\n",
      "686   13  50\n",
      "687   14  53\n",
      "pm2 MER\n",
      "1   Hora MER\n",
      "674    1  23\n",
      "675    2  20\n",
      "676    3  17\n",
      "677    4  29\n",
      "678    5  20\n",
      "679    6  15\n",
      "680    7  19\n",
      "681    8  21\n",
      "682    9  20\n",
      "683   10  24\n",
      "684   11  16\n",
      "685   12  32\n",
      "686   13  nr\n",
      "687   14   4\n",
      "pm2 UIZ\n",
      "1   Hora UIZ\n",
      "674    1  24\n",
      "675    2  24\n",
      "676    3  21\n",
      "677    4  23\n",
      "678    5  18\n",
      "679    6  19\n",
      "680    7  15\n",
      "681    8  15\n",
      "682    9  17\n",
      "683   10  28\n",
      "684   11  30\n",
      "685   12  38\n",
      "686   13  24\n",
      "687   14  28\n",
      "rh MER\n",
      "1   Hora MER\n",
      "674    1  34\n",
      "675    2  37\n",
      "676    3  39\n",
      "677    4  39\n",
      "678    5  41\n",
      "679    6  44\n",
      "680    7  45\n",
      "681    8  44\n",
      "682    9  39\n",
      "683   10  33\n",
      "684   11  28\n",
      "685   12  23\n",
      "686   13  nr\n",
      "687   14  16\n",
      "rh UIZ\n",
      "1   Hora UIZ\n",
      "674    1  41\n",
      "675    2  42\n",
      "676    3  46\n",
      "677    4  46\n",
      "678    5  49\n",
      "679    6  52\n",
      "680    7  54\n",
      "681    8  52\n",
      "682    9  50\n",
      "683   10  43\n",
      "684   11  34\n",
      "685   12  27\n",
      "686   13  22\n",
      "687   14  20\n",
      "so2 MER\n",
      "1   Hora MER\n",
      "674    1  nr\n",
      "675    2  nr\n",
      "676    3  nr\n",
      "677    4   3\n",
      "678    5   2\n",
      "679    6   3\n",
      "680    7   4\n",
      "681    8   4\n",
      "682    9   4\n",
      "683   10   3\n",
      "684   11   3\n",
      "685   12   3\n",
      "686   13  nr\n",
      "687   14   2\n",
      "so2 UIZ\n",
      "1   Hora UIZ\n",
      "674    1  nr\n",
      "675    2  nr\n",
      "676    3  nr\n",
      "677    4   1\n",
      "678    5   1\n",
      "679    6   1\n",
      "680    7   1\n",
      "681    8   2\n",
      "682    9   4\n",
      "683   10   2\n",
      "684   11   2\n",
      "685   12   2\n",
      "686   13   2\n",
      "687   14   1\n",
      "tmp MER\n",
      "1   Hora MER\n",
      "674    1  17\n",
      "675    2  16\n",
      "676    3  16\n",
      "677    4  15\n",
      "678    5  14\n",
      "679    6  13\n",
      "680    7  14\n",
      "681    8  14\n",
      "682    9  16\n",
      "683   10  18\n",
      "684   11  19\n",
      "685   12  22\n",
      "686   13  nr\n",
      "687   14  25\n",
      "tmp UIZ\n",
      "1   Hora UIZ\n",
      "674    1  17\n",
      "675    2  17\n",
      "676    3  16\n",
      "677    4  15\n",
      "678    5  15\n",
      "679    6  14\n",
      "680    7  14\n",
      "681    8  14\n",
      "682    9  15\n",
      "683   10  17\n",
      "684   11  20\n",
      "685   12  22\n",
      "686   13  24\n",
      "687   14  25\n",
      "wdr MER\n",
      "1   Hora  MER\n",
      "674    1  196\n",
      "675    2  178\n",
      "676    3  200\n",
      "677    4  182\n",
      "678    5  184\n",
      "679    6  175\n",
      "680    7  184\n",
      "681    8  188\n",
      "682    9  195\n",
      "683   10  203\n",
      "684   11  123\n",
      "685   12  120\n",
      "686   13   nr\n",
      "687   14  180\n",
      "wdr UIZ\n",
      "1   Hora  UIZ\n",
      "674    1  208\n",
      "675    2  191\n",
      "676    3  195\n",
      "677    4  234\n",
      "678    5  172\n",
      "679    6  187\n",
      "680    7  201\n",
      "681    8  227\n",
      "682    9  283\n",
      "683   10  342\n",
      "684   11   85\n",
      "685   12  109\n",
      "686   13   66\n",
      "687   14  274\n",
      "wsp MER\n",
      "1   Hora  MER\n",
      "674    1  1.2\n",
      "675    2  1.1\n",
      "676    3  0.7\n",
      "677    4  1.3\n",
      "678    5  1.3\n",
      "679    6  0.7\n",
      "680    7  1.3\n",
      "681    8  0.5\n",
      "682    9  0.8\n",
      "683   10  0.8\n",
      "684   11    1\n",
      "685   12  1.4\n",
      "686   13   nr\n",
      "687   14  1.9\n",
      "wsp UIZ\n",
      "1   Hora  UIZ\n",
      "674    1  1.9\n",
      "675    2  1.9\n",
      "676    3  1.3\n",
      "677    4    1\n",
      "678    5  0.9\n",
      "679    6  1.2\n",
      "680    7  1.9\n",
      "681    8    1\n",
      "682    9  0.9\n",
      "683   10    1\n",
      "684   11  1.1\n",
      "685   12  1.4\n",
      "686   13  1.6\n",
      "687   14    2\n",
      "Datos gob\n",
      "  station                             date    CO NO NOX NO2  O3 PM10 PM25  RH  \\\n",
      "0     MER 2025-01-29 14:08:52.268225-06:00  0.61  4  31  27  73   13    4  16   \n",
      "1     UIZ 2025-01-29 14:08:52.268225-06:00  0.48  2  16  15  77   53   28  20   \n",
      "\n",
      "  SO2 TMP  WDR  WSP  year month day hour minutes traffic  \n",
      "0   2  25  180  1.9  2025     1  29   14       0     NaN  \n",
      "1   1  25  274    2  2025     1  29   14       0     NaN  \n"
     ]
    }
   ],
   "source": [
    "station = \"MER\"\n",
    "\n",
    "for cont in claveCont:\n",
    "    urlGob = f\"http://www.aire.cdmx.gob.mx/estadisticas-consultas/concentraciones/respuesta.php?qtipo=HORARIOS&parametro={cont}&anio={year}&qmes={month}\"\n",
    "    \n",
    "    #print(urlGob)\n",
    "    df_consulta = pd.read_html(urlGob, encoding='windows-1252')\n",
    "\n",
    "    df_datos = df_consulta[0]\n",
    "\n",
    "    df_datos.columns = df_datos.iloc[1]\n",
    "\n",
    "    df_datos = df_datos.drop([0,1])\n",
    "\n",
    "    #print(df_datos.head())\n",
    "\n",
    "    #Nombre de la culmna del contaminante en el dataframe de estaciones\n",
    "    if(cont == \"pm2\"):\n",
    "        colEstation = \"PM25\"\n",
    "    else: \n",
    "        colEstation = cont.upper()\n",
    "\n",
    "\n",
    "    for station in stations2forecast:\n",
    "        dataofDay = df_datos.loc[df_datos['Fecha'] == dateData, [\"Hora\",station]]\n",
    "\n",
    "        print(cont,station)\n",
    "        #print(dataofDay)\n",
    "        #float(dataofDay.loc[dataofDay['Hora'] == hour, station].values[0])\n",
    "        dato = dataofDay.loc[dataofDay['Hora'] == hour, station].values[0]\n",
    "        if(dato != \"nr\"):\n",
    "            if float(dato) >= 0:\n",
    "                contEstacion.loc[contEstacion['station'] == station, colEstation] = dato\n",
    "            else: \n",
    "                contEstacion.loc[contEstacion['station'] == station, colEstation] = np.nan\n",
    "        else: \n",
    "            contEstacion.loc[contEstacion['station'] == station, colEstation] = np.nan\n",
    "print(\"Datos gob\")\n",
    "print(contEstacion.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "        try:\n",
    "\n",
    "            datetime_now = datetime.now(tz_mexico)\n",
    "            year = str(datetime_now.year)\n",
    "            date_df = datetime_now.strftime('%Y-%m-%d')\n",
    "            year = str(datetime_now.year)\n",
    "            month = str(datetime_now.month)\n",
    "            day = str(datetime_now.day)\n",
    "            hour = str(datetime_now.hour)\n",
    "            minute= str(datetime_now.minute)\n",
    "\n",
    "            #Preparar datos para buscar tabla\n",
    "            dayText = f'0{day}' if len(str(day)) == 1 else str(day)\n",
    "            monthText = f'0{month}' if len(str(month))  == 1 else str(month)\n",
    "            dateData = f'{dayText}-{monthText}-{year}'\n",
    "            \n",
    "            claveCont = ['co','no','nox','no2','o3','pm10','pm2','rh','so2','tmp','wdr','wsp']\n",
    "\n",
    "            #Crear dataframe vacio por estacion\n",
    "\n",
    "            contEstacion = pd.DataFrame(columns=[\"station\",\"date\", \"CO\", \"NO\", \"NOX\",\"NO2\", \"O3\", \"PM10\", \"PM25\", \"RH\", \"SO2\", \"TMP\", \"WDR\", \"WSP\", \"year\", \"month\", \"day\", \"hour\", \"minutes\", \"traffic\"])\n",
    "\n",
    "            for station in stations2forecast:\n",
    "                contEstacion = pd.concat([contEstacion, pd.DataFrame({\"station\":station,\n",
    "                                                        \"date\":datetime_now,\n",
    "                                                        \"year\":year,\n",
    "                                                        \"month\":month,\n",
    "                                                        \"day\":day,\n",
    "                                                        \"hour\":hour,\n",
    "                                                        \"minutes\":\"0\"}, index=[0])], ignore_index=True)\n",
    "        \n",
    "            #print(contEstacion.head())\n",
    "\n",
    "            for cont in claveCont:\n",
    "                urlGob = f\"http://www.aire.cdmx.gob.mx/estadisticas-consultas/concentraciones/respuesta.php?qtipo=HORARIOS&parametro={cont}&anio={year}&qmes={month}\"\n",
    "                \n",
    "                #print(urlGob)\n",
    "                df_consulta = pd.read_html(urlGob, encoding='windows-1252')\n",
    "\n",
    "                df_datos = df_consulta[0]\n",
    "\n",
    "                df_datos.columns = df_datos.iloc[1]\n",
    "\n",
    "                df_datos = df_datos.drop([0,1])\n",
    "\n",
    "                #print(df_datos.head())\n",
    "\n",
    "                #Nombre de la culmna del contaminante en el dataframe de estaciones\n",
    "                if(cont == \"pm2\"):\n",
    "                    colEstation = \"PM25\"\n",
    "                else: \n",
    "                    colEstation = cont.upper()\n",
    "\n",
    "\n",
    "                for station in stations2forecast:\n",
    "                    dataofDay = df_datos.loc[df_datos['Fecha'] == dateData, [\"Hora\",station]]\n",
    "                    dato = dataofDay.loc[dataofDay['Hora'] == hour, station]\n",
    "                    print(dato)\n",
    "                    dato = dato.values[0]\n",
    "\n",
    "                    if(dato != \"nr\"):\n",
    "                        if float(dato) >= 0:\n",
    "                            contEstacion.loc[contEstacion['station'] == station, colEstation] = dato\n",
    "                        else: \n",
    "                            contEstacion.loc[contEstacion['station'] == station, colEstation] = np.nan\n",
    "                    else: \n",
    "                        contEstacion.loc[contEstacion['station'] == station, colEstation] = np.nan\n",
    "            print(\"Datos gob\")\n",
    "            print(contEstacion.tail())\n",
    "            #\"CO\", \"NO\", \"NOX\",\"NO2\", \"O3\", \"PM10\", \"PM25\", \"RH\", \"SO2\", \"TMP\", \"WDR\", \"WSP\", \"year\", \"month\", \"day\", \"hour\", \"minutes\", \"traffic\"])\n",
    "                \n",
    "            CO =contEstacion.loc[contEstacion['station'] == station,\"CO\"].values[0]\n",
    "            NO = contEstacion.loc[contEstacion['station'] == station,\"NO\"].values[0]\n",
    "            NOX = contEstacion.loc[contEstacion['station'] == station,\"NOX\"].values[0]\n",
    "            NO2= contEstacion.loc[contEstacion['station'] == station,\"NO2\"].values[0]\n",
    "            O3= contEstacion.loc[contEstacion['station'] == station,\"O3\"].values[0]\n",
    "            PM10 =contEstacion.loc[contEstacion['station'] == station,\"PM10\"].values[0]\n",
    "            PM25 = contEstacion.loc[contEstacion['station'] == station,\"PM25\"].values[0]\n",
    "            RH = contEstacion.loc[contEstacion['station'] == station,\"RH\"].values[0]\n",
    "            SO2= contEstacion.loc[contEstacion['station'] == station,\"SO2\"].values[0]\n",
    "            TMP = contEstacion.loc[contEstacion['station'] == station,\"TMP\"].values[0]\n",
    "            WDR = contEstacion.loc[contEstacion['station'] == station,\"WDR\"].values[0]\n",
    "            WSP= contEstacion.loc[contEstacion['station'] == station,\"WSP\"].values[0]\n",
    "            print(\"GOB\")\n",
    "            print(CO, NO, NO2, NOX,O3, PM10, PM25, RH, SO2, TMP, WDR, WSP)\n",
    "        except:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        min_val = loaded_scaler.data_min_[4]  # Valor mínimo del O3\n",
    "        max_val = loaded_scaler.data_max_[4]  # Valor máximo del O3\n",
    "        # Aplicar la transformación inversa \n",
    "        predicciones = predicciones_normalizadas * (max_val - min_val) + min_val\n",
    "        #y_test_normalizadas = y_test.reshape(-1, 1)\n",
    "        #y_test = loaded_scaler.inverse_transform(y_test_normalizadas)\n",
    "        y_test = y_test * (max_val - min_val) + min_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
