{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import shutil\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean las carpetas en blanco para guardar los nuevos archivos modificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datos_Modificados\\CO\n",
      "2024 datos_Modificados\\CO\\2024 0\n",
      "datos_Modificados\\NO\n",
      "2024 datos_Modificados\\NO\\2024 0\n",
      "datos_Modificados\\NO2\n",
      "2024 datos_Modificados\\NO2\\2024 0\n",
      "datos_Modificados\\NOX\n",
      "2024 datos_Modificados\\NOX\\2024 0\n",
      "datos_Modificados\\O3\n",
      "2024 datos_Modificados\\O3\\2024 0\n",
      "datos_Modificados\\PM2.5\n",
      "2024 datos_Modificados\\PM2.5\\2024 0\n",
      "datos_Modificados\\PM10\n",
      "2024 datos_Modificados\\PM10\\2024 0\n",
      "datos_Modificados\\RH\n",
      "2024 datos_Modificados\\RH\\2024 0\n",
      "datos_Modificados\\SO2\n",
      "2024 datos_Modificados\\SO2\\2024 0\n",
      "datos_Modificados\\TMP\n",
      "2024 datos_Modificados\\TMP\\2024 0\n",
      "datos_Modificados\\WDR\n",
      "2024 datos_Modificados\\WDR\\2024 0\n",
      "datos_Modificados\\WSP\n",
      "2024 datos_Modificados\\WSP\\2024 0\n"
     ]
    }
   ],
   "source": [
    "#Crear carpetas en blanco\n",
    "\n",
    "dir = \"datos_Modificados\"\n",
    "if not os.path.exists(dir):\n",
    "    os.makedirs(dir)\n",
    "\n",
    "pollutants = [\"CO\", \"NO\", \"NO2\", \"NOX\", \"O3\", \"PM2.5\", \"PM10\", \"RH\", \"SO2\", \"TMP\", \"WDR\", \"WSP\"]\n",
    "for pollutant in pollutants:\n",
    "    pollutant_path = os.path.join(dir, pollutant)\n",
    "    print(pollutant_path)\n",
    "    os.makedirs(pollutant_path)\n",
    "    year = 2024\n",
    "    for y in range(1):\n",
    "        year_path = os.path.join(pollutant_path, str(year+y))\n",
    "        os.makedirs(year_path)\n",
    "        print(year, year_path, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los archivos descargados de la página aire y salud tiene una fila al inicio y dos al final que no pertenecen a la tabla de valores (el título e información pareciera de html),\n",
    "por lo que se eliminan para que se puedan leer como dataframes con pandas, de otra forma causa error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_rows(dir, new_dir, file_path):\n",
    "    filas = []\n",
    "    dataframe = pd.read_csv(file_path)\n",
    "    num_rows = len(dataframe)\n",
    "    print(num_rows, file_path)\n",
    "    with open(file_path, 'r', newline='', encoding='utf-8') as archivo_csv:\n",
    "        lector_csv = csv.reader(archivo_csv)\n",
    "        for row in lector_csv:\n",
    "            if \"Promedio\" in row[0]:\n",
    "                print(row[0])    \n",
    "            elif \"<br\" in row[0]:\n",
    "                print(row[0])  \n",
    "            elif \"<b\" in row[0]:\n",
    "                print(row[0])          \n",
    "            else:\n",
    "                filas.append(row)\n",
    "\n",
    "\n",
    "    subpath = file_path[len(dir):len(file_path)]\n",
    "    new_path = os.path.join(new_dir, subpath)\n",
    "    \n",
    "    with open(new_path, 'w', newline='', encoding='utf-8') as archivo_csv_nuevo:\n",
    "        escritor_csv = csv.writer(archivo_csv_nuevo)\n",
    "        escritor_csv.writerows(filas)\n",
    "\n",
    "    dataframe = pd.read_csv(new_path)\n",
    "    num_rows = len(dataframe)\n",
    "    print(num_rows)\n",
    "    return dataframe, new_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cambia el nombre de todos los archivos descargados (todos dicen Promedio_contaminanteX), por el nombre del contaminante_el mes_año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datos_Modificados/CO\\2024\\Promedio horarios de co (1).csv CO 2024\n",
      "745 datos_Modificados/CO\\2024\\Promedio horarios de co (1).csv\n",
      "Promedio horarios de coPromedio horarios de co\n",
      "744\n",
      "datos_Modificados/CO\\2024\\Promedio horarios de co (3).csv CO 2024\n",
      "745 datos_Modificados/CO\\2024\\Promedio horarios de co (3).csv\n",
      "Promedio horarios de coPromedio horarios de co\n",
      "744\n",
      "datos_Modificados/CO\\2024\\Promedio horarios de co (4).csv CO 2024\n",
      "714 datos_Modificados/CO\\2024\\Promedio horarios de co (4).csv\n",
      "Promedio horarios de coPromedio horarios de co\n",
      "713\n",
      "datos_Modificados/CO\\2024\\Promedio horarios de co.csv CO 2024\n",
      "721 datos_Modificados/CO\\2024\\Promedio horarios de co.csv\n",
      "Promedio horarios de coPromedio horarios de co\n",
      "720\n",
      "datos_Modificados/NO\\2024\\Promedio horarios de no (1).csv NO 2024\n",
      "745 datos_Modificados/NO\\2024\\Promedio horarios de no (1).csv\n",
      "Promedio horarios de noPromedio horarios de no\n",
      "744\n",
      "datos_Modificados/NO\\2024\\Promedio horarios de no (3).csv NO 2024\n",
      "745 datos_Modificados/NO\\2024\\Promedio horarios de no (3).csv\n",
      "Promedio horarios de noPromedio horarios de no\n",
      "744\n",
      "datos_Modificados/NO\\2024\\Promedio horarios de no (4).csv NO 2024\n",
      "714 datos_Modificados/NO\\2024\\Promedio horarios de no (4).csv\n",
      "Promedio horarios de noPromedio horarios de no\n",
      "713\n",
      "datos_Modificados/NO\\2024\\Promedio horarios de no.csv NO 2024\n",
      "721 datos_Modificados/NO\\2024\\Promedio horarios de no.csv\n",
      "Promedio horarios de noPromedio horarios de no\n",
      "720\n",
      "datos_Modificados/NO2\\2024\\Promedio horarios de no2 (1).csv NO2 2024\n",
      "745 datos_Modificados/NO2\\2024\\Promedio horarios de no2 (1).csv\n",
      "Promedio horarios de no2Promedio horarios de no2\n",
      "744\n",
      "datos_Modificados/NO2\\2024\\Promedio horarios de no2 (3).csv NO2 2024\n",
      "745 datos_Modificados/NO2\\2024\\Promedio horarios de no2 (3).csv\n",
      "Promedio horarios de no2Promedio horarios de no2\n",
      "744\n",
      "datos_Modificados/NO2\\2024\\Promedio horarios de no2 (4).csv NO2 2024\n",
      "714 datos_Modificados/NO2\\2024\\Promedio horarios de no2 (4).csv\n",
      "Promedio horarios de no2Promedio horarios de no2\n",
      "713\n",
      "datos_Modificados/NO2\\2024\\Promedio horarios de no2.csv NO2 2024\n",
      "721 datos_Modificados/NO2\\2024\\Promedio horarios de no2.csv\n",
      "Promedio horarios de no2Promedio horarios de no2\n",
      "720\n",
      "datos_Modificados/NOX\\2024\\Promedio horarios de nox (1).csv NOX 2024\n",
      "745 datos_Modificados/NOX\\2024\\Promedio horarios de nox (1).csv\n",
      "Promedio horarios de noxPromedio horarios de nox\n",
      "744\n",
      "datos_Modificados/NOX\\2024\\Promedio horarios de nox (3).csv NOX 2024\n",
      "745 datos_Modificados/NOX\\2024\\Promedio horarios de nox (3).csv\n",
      "Promedio horarios de noxPromedio horarios de nox\n",
      "744\n",
      "datos_Modificados/NOX\\2024\\Promedio horarios de nox (4).csv NOX 2024\n",
      "714 datos_Modificados/NOX\\2024\\Promedio horarios de nox (4).csv\n",
      "Promedio horarios de noxPromedio horarios de nox\n",
      "713\n",
      "datos_Modificados/NOX\\2024\\Promedio horarios de nox.csv NOX 2024\n",
      "721 datos_Modificados/NOX\\2024\\Promedio horarios de nox.csv\n",
      "Promedio horarios de noxPromedio horarios de nox\n",
      "720\n",
      "datos_Modificados/O3\\2024\\Promedio horarios de o3 (1).csv O3 2024\n",
      "745 datos_Modificados/O3\\2024\\Promedio horarios de o3 (1).csv\n",
      "Promedio horarios de o3Promedio horarios de o3\n",
      "744\n",
      "datos_Modificados/O3\\2024\\Promedio horarios de o3 (3).csv O3 2024\n",
      "745 datos_Modificados/O3\\2024\\Promedio horarios de o3 (3).csv\n",
      "Promedio horarios de o3Promedio horarios de o3\n",
      "744\n",
      "datos_Modificados/O3\\2024\\Promedio horarios de o3 (4).csv O3 2024\n",
      "714 datos_Modificados/O3\\2024\\Promedio horarios de o3 (4).csv\n",
      "Promedio horarios de o3Promedio horarios de o3\n",
      "713\n",
      "datos_Modificados/O3\\2024\\Promedio horarios de o3.csv O3 2024\n",
      "721 datos_Modificados/O3\\2024\\Promedio horarios de o3.csv\n",
      "Promedio horarios de o3Promedio horarios de o3\n",
      "720\n",
      "datos_Modificados/PM10\\2024\\Promedio horarios de pm10 (1).csv PM10 2024\n",
      "745 datos_Modificados/PM10\\2024\\Promedio horarios de pm10 (1).csv\n",
      "Promedio horarios de pm10Promedio horarios de pm10\n",
      "744\n",
      "datos_Modificados/PM10\\2024\\Promedio horarios de pm10 (3).csv PM10 2024\n",
      "745 datos_Modificados/PM10\\2024\\Promedio horarios de pm10 (3).csv\n",
      "Promedio horarios de pm10Promedio horarios de pm10\n",
      "744\n",
      "datos_Modificados/PM10\\2024\\Promedio horarios de pm10 (4).csv PM10 2024\n",
      "714 datos_Modificados/PM10\\2024\\Promedio horarios de pm10 (4).csv\n",
      "Promedio horarios de pm10Promedio horarios de pm10\n",
      "713\n",
      "datos_Modificados/PM10\\2024\\Promedio horarios de pm10.csv PM10 2024\n",
      "721 datos_Modificados/PM10\\2024\\Promedio horarios de pm10.csv\n",
      "Promedio horarios de pm10Promedio horarios de pm10\n",
      "720\n",
      "datos_Modificados/PM2.5\\2024\\Promedio horarios de pm2 (1).csv PM2.5 2024\n",
      "745 datos_Modificados/PM2.5\\2024\\Promedio horarios de pm2 (1).csv\n",
      "Promedio horarios de pm2Promedio horarios de pm2\n",
      "744\n",
      "datos_Modificados/PM2.5\\2024\\Promedio horarios de pm2 (3).csv PM2.5 2024\n",
      "745 datos_Modificados/PM2.5\\2024\\Promedio horarios de pm2 (3).csv\n",
      "Promedio horarios de pm2Promedio horarios de pm2\n",
      "744\n",
      "datos_Modificados/PM2.5\\2024\\Promedio horarios de pm2 (4).csv PM2.5 2024\n",
      "714 datos_Modificados/PM2.5\\2024\\Promedio horarios de pm2 (4).csv\n",
      "Promedio horarios de pm2Promedio horarios de pm2\n",
      "713\n",
      "datos_Modificados/PM2.5\\2024\\Promedio horarios de pm2.csv PM2.5 2024\n",
      "721 datos_Modificados/PM2.5\\2024\\Promedio horarios de pm2.csv\n",
      "Promedio horarios de pm2Promedio horarios de pm2\n",
      "720\n",
      "datos_Modificados/RH\\2024\\Promedio horarios de rh (1).csv RH 2024\n",
      "745 datos_Modificados/RH\\2024\\Promedio horarios de rh (1).csv\n",
      "Promedio horarios de rhPromedio horarios de rh\n",
      "744\n",
      "datos_Modificados/RH\\2024\\Promedio horarios de rh (3).csv RH 2024\n",
      "745 datos_Modificados/RH\\2024\\Promedio horarios de rh (3).csv\n",
      "Promedio horarios de rhPromedio horarios de rh\n",
      "744\n",
      "datos_Modificados/RH\\2024\\Promedio horarios de rh (4).csv RH 2024\n",
      "714 datos_Modificados/RH\\2024\\Promedio horarios de rh (4).csv\n",
      "Promedio horarios de rhPromedio horarios de rh\n",
      "713\n",
      "datos_Modificados/RH\\2024\\Promedio horarios de rh.csv RH 2024\n",
      "721 datos_Modificados/RH\\2024\\Promedio horarios de rh.csv\n",
      "Promedio horarios de rhPromedio horarios de rh\n",
      "720\n",
      "datos_Modificados/SO2\\2024\\Promedio horarios de so2 (1).csv SO2 2024\n",
      "745 datos_Modificados/SO2\\2024\\Promedio horarios de so2 (1).csv\n",
      "Promedio horarios de so2Promedio horarios de so2\n",
      "744\n",
      "datos_Modificados/SO2\\2024\\Promedio horarios de so2 (2).csv SO2 2024\n",
      "745 datos_Modificados/SO2\\2024\\Promedio horarios de so2 (2).csv\n",
      "Promedio horarios de so2Promedio horarios de so2\n",
      "744\n",
      "datos_Modificados/SO2\\2024\\Promedio horarios de so2 (5).csv SO2 2024\n",
      "714 datos_Modificados/SO2\\2024\\Promedio horarios de so2 (5).csv\n",
      "Promedio horarios de so2Promedio horarios de so2\n",
      "713\n",
      "datos_Modificados/SO2\\2024\\Promedio horarios de so2.csv SO2 2024\n",
      "721 datos_Modificados/SO2\\2024\\Promedio horarios de so2.csv\n",
      "Promedio horarios de so2Promedio horarios de so2\n",
      "720\n",
      "datos_Modificados/TMP\\2024\\Promedio horarios de tmp (1).csv TMP 2024\n",
      "745 datos_Modificados/TMP\\2024\\Promedio horarios de tmp (1).csv\n",
      "Promedio horarios de tmpPromedio horarios de tmp\n",
      "744\n",
      "datos_Modificados/TMP\\2024\\Promedio horarios de tmp (3).csv TMP 2024\n",
      "745 datos_Modificados/TMP\\2024\\Promedio horarios de tmp (3).csv\n",
      "Promedio horarios de tmpPromedio horarios de tmp\n",
      "744\n",
      "datos_Modificados/TMP\\2024\\Promedio horarios de tmp (4).csv TMP 2024\n",
      "714 datos_Modificados/TMP\\2024\\Promedio horarios de tmp (4).csv\n",
      "Promedio horarios de tmpPromedio horarios de tmp\n",
      "713\n",
      "datos_Modificados/TMP\\2024\\Promedio horarios de tmp.csv TMP 2024\n",
      "721 datos_Modificados/TMP\\2024\\Promedio horarios de tmp.csv\n",
      "Promedio horarios de tmpPromedio horarios de tmp\n",
      "720\n",
      "datos_Modificados/WDR\\2024\\Promedio horarios de wdr (1).csv WDR 2024\n",
      "745 datos_Modificados/WDR\\2024\\Promedio horarios de wdr (1).csv\n",
      "Promedio horarios de wdrPromedio horarios de wdr\n",
      "744\n",
      "datos_Modificados/WDR\\2024\\Promedio horarios de wdr (3).csv WDR 2024\n",
      "714 datos_Modificados/WDR\\2024\\Promedio horarios de wdr (3).csv\n",
      "Promedio horarios de wdrPromedio horarios de wdr\n",
      "713\n",
      "datos_Modificados/WDR\\2024\\Promedio horarios de wdr (4).csv WDR 2024\n",
      "745 datos_Modificados/WDR\\2024\\Promedio horarios de wdr (4).csv\n",
      "Promedio horarios de wdrPromedio horarios de wdr\n",
      "744\n",
      "datos_Modificados/WDR\\2024\\Promedio horarios de wdr.csv WDR 2024\n",
      "721 datos_Modificados/WDR\\2024\\Promedio horarios de wdr.csv\n",
      "Promedio horarios de wdrPromedio horarios de wdr\n",
      "720\n",
      "datos_Modificados/WSP\\2024\\Promedio horarios de wsp (1).csv WSP 2024\n",
      "745 datos_Modificados/WSP\\2024\\Promedio horarios de wsp (1).csv\n",
      "Promedio horarios de wspPromedio horarios de wsp\n",
      "744\n",
      "datos_Modificados/WSP\\2024\\Promedio horarios de wsp (3).csv WSP 2024\n",
      "745 datos_Modificados/WSP\\2024\\Promedio horarios de wsp (3).csv\n",
      "Promedio horarios de wspPromedio horarios de wsp\n",
      "744\n",
      "datos_Modificados/WSP\\2024\\Promedio horarios de wsp (4).csv WSP 2024\n",
      "714 datos_Modificados/WSP\\2024\\Promedio horarios de wsp (4).csv\n",
      "Promedio horarios de wspPromedio horarios de wsp\n",
      "713\n",
      "datos_Modificados/WSP\\2024\\Promedio horarios de wsp.csv WSP 2024\n",
      "721 datos_Modificados/WSP\\2024\\Promedio horarios de wsp.csv\n",
      "Promedio horarios de wspPromedio horarios de wsp\n",
      "720\n"
     ]
    }
   ],
   "source": [
    "dir = \"datos_Modificados/\"\n",
    "#dir = \"Datos Aire y Salud/\"\n",
    "new_dir = \"datos_Modificados/\"\n",
    "\n",
    "\n",
    "for actual_folder, folders, files in os.walk(dir):\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(actual_folder, file_name)\n",
    "        if file_path.endswith(\".csv\"):\n",
    "            sub_folders = file_path.split(\"/\")\n",
    "            sub_folders = sub_folders[len(sub_folders)-1].split(\"\\\\\")\n",
    "            variable = sub_folders[len(sub_folders)-3]\n",
    "            year = sub_folders[len(sub_folders)-2]\n",
    "            print(file_path, variable, year)\n",
    "\n",
    "            try:\n",
    "                dataframe, new_path = delete_rows(dir, new_dir, file_path)\n",
    "            except:                \n",
    "                subpath = file_path[len(dir):len(file_path)]\n",
    "                path = os.path.join(new_dir, subpath)\n",
    "                new_path = os.path.split(path)\n",
    "                new_path = new_path[0]\n",
    "                new_path = shutil.copy(file_path, new_path)\n",
    "                dataframe = pd.read_csv(new_path)\n",
    "            if file_name.startswith(\"Promedio\"):\n",
    "                months = {\"01\":\"JAN\", \"02\":\"FEB\", \"03\":\"MAR\", \"04\":\"APR\", \"05\":\"MAY\", \"06\":\"JUN\", \"07\":\"JUL\", \"08\":\"AUG\", \"09\":\"SEP\", \"10\":\"OCT\", \"11\":\"NOV\", \"12\":\"DEC\"}\n",
    "                date = dataframe.iloc[0].Fecha\n",
    "                num_month = date.split(\"-\")\n",
    "                month = months[num_month[1]]\n",
    "\n",
    "                new_name = os.path.join(new_dir,variable)\n",
    "                new_name = os.path.join(new_name, year)\n",
    "                name = variable + \"_\" +month+\"_\"+year + \".csv\"\n",
    "                new_name = os.path.join(new_name, name)\n",
    "                os.rename(new_path,new_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se juntan POR CONTAMINANTE en un solo dataframe los datos de todos los meses y todos los año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = \"datos_Modificados\"\n",
    "files_path = \"Archivos_contaminantes_juntas\"\n",
    "\n",
    "if not os.path.exists(files_path):\n",
    "    os.makedirs(files_path)\n",
    "    \n",
    "CO_dataframes = []\n",
    "SO2_dataframes = []\n",
    "NO_dataframes = []\n",
    "NOX_dataframes = []\n",
    "NO2_dataframes = []\n",
    "PM10_dataframes = []\n",
    "PM25_dataframes = []\n",
    "O3_dataframes = []\n",
    "RH_dataframes = []\n",
    "WDR_dataframes = []\n",
    "WSP_dataframes = []\n",
    "TMP_dataframes = []\n",
    "\n",
    "\n",
    "for actual_folder, folders, files in os.walk(new_dir):\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(actual_folder, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        if \"CO\" in file_name:\n",
    "            CO_dataframes.append(df)\n",
    "        elif \"NOX\" in file_name:\n",
    "            NOX_dataframes.append(df)\n",
    "        elif \"NO2\" in file_name:\n",
    "            NO2_dataframes.append(df)\n",
    "        elif \"NO\" in file_name:\n",
    "            NO_dataframes.append(df)\n",
    "        elif \"O3\" in file_name:\n",
    "            O3_dataframes.append(df)\n",
    "        elif \"PM10\" in file_name:\n",
    "            PM10_dataframes.append(df)\n",
    "        elif \"PM2.5\" in file_name:\n",
    "            PM25_dataframes.append(df)\n",
    "        elif \"TMP\" in file_name:\n",
    "            TMP_dataframes.append(df)\n",
    "        elif \"WSP\" in file_name:\n",
    "            WSP_dataframes.append(df)\n",
    "        elif \"WDR\" in file_name:\n",
    "            WDR_dataframes.append(df)\n",
    "        elif \"RH\" in file_name:\n",
    "            RH_dataframes.append(df)\n",
    "        elif \"SO2\" in file_name:\n",
    "            SO2_dataframes.append(df)\n",
    "\n",
    "df_final_CO = pd.concat(CO_dataframes, ignore_index=True, sort=False)\n",
    "df_final_NO = pd.concat(NO_dataframes, ignore_index=True, sort=False)\n",
    "df_final_NO2 = pd.concat(NO2_dataframes, ignore_index=True, sort=False)\n",
    "df_final_NOX = pd.concat(NOX_dataframes, ignore_index=True, sort=False)\n",
    "df_final_SO2 = pd.concat(SO2_dataframes, ignore_index=True, sort=False)\n",
    "df_final_O3 = pd.concat(O3_dataframes, ignore_index=True, sort=False)\n",
    "df_final_PM10 = pd.concat(PM10_dataframes, ignore_index=True, sort=False)\n",
    "df_final_PM25 = pd.concat(PM25_dataframes, ignore_index=True, sort=False)\n",
    "df_final_TMP = pd.concat(TMP_dataframes, ignore_index=True, sort=False)\n",
    "df_final_WDR = pd.concat(WDR_dataframes, ignore_index=True, sort=False)\n",
    "df_final_WSP = pd.concat(WSP_dataframes, ignore_index=True, sort=False)\n",
    "df_final_RH = pd.concat(RH_dataframes, ignore_index=True, sort=False)\n",
    "\n",
    "\n",
    "file_name_CO = os.path.join(files_path,\"CO.csv\")\n",
    "file_name_O3 = os.path.join(files_path,\"O3.csv\")\n",
    "file_name_NO = os.path.join(files_path,\"NO.csv\")\n",
    "file_name_NO2 = os.path.join(files_path,\"NO2.csv\")\n",
    "file_name_NOX = os.path.join(files_path,\"NOX.csv\")\n",
    "file_name_PM10 = os.path.join(files_path,\"PM10.csv\")\n",
    "file_name_PM25 = os.path.join(files_path,\"PM25.csv\")\n",
    "file_name_TMP = os.path.join(files_path,\"TMP.csv\")\n",
    "file_name_WDR = os.path.join(files_path,\"WDR.csv\")\n",
    "file_name_WSP = os.path.join(files_path,\"WSP.csv\")\n",
    "file_name_RH = os.path.join(files_path,\"RH.csv\")\n",
    "file_name_SO2 = os.path.join(files_path,\"SO2.csv\")\n",
    "\n",
    "df_final_CO.to_csv(file_name_CO, index=False)\n",
    "df_final_SO2.to_csv(file_name_SO2, index=False)\n",
    "df_final_NO.to_csv(file_name_NO, index=False)\n",
    "df_final_NO2.to_csv(file_name_NO2, index=False)\n",
    "df_final_NOX.to_csv(file_name_NOX, index=False)\n",
    "df_final_O3.to_csv(file_name_O3, index=False)\n",
    "df_final_PM10.to_csv(file_name_PM10, index=False)\n",
    "df_final_PM25.to_csv(file_name_PM25, index=False)\n",
    "df_final_TMP.to_csv(file_name_TMP, index=False)\n",
    "df_final_WSP.to_csv(file_name_WSP, index=False)\n",
    "df_final_WDR.to_csv(file_name_WDR, index=False)\n",
    "df_final_RH.to_csv(file_name_RH, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cambian los datos vacios con valor de \"nr\" por NaN, y se separa la fecha en columnas de día, mes, año, y se crea una nueva con los datos de la fecha y la hora para poder ordenarlos de forma ascendente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guarda toda la info de todos los contaminantes en un solo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna 'fecha_hora' no tiene valores NaN.\n",
      "La columna 'fecha_hora' no tiene valores NaN.\n",
      "La columna 'fecha_hora' no tiene valores NaN.\n",
      "La columna 'fecha_hora' no tiene valores NaN.\n",
      "La columna 'fecha_hora' no tiene valores NaN.\n",
      "La columna 'fecha_hora' no tiene valores NaN.\n",
      "La columna 'fecha_hora' no tiene valores NaN.\n",
      "La columna 'fecha_hora' no tiene valores NaN.\n",
      "La columna 'fecha_hora' no tiene valores NaN.\n",
      "La columna 'fecha_hora' no tiene valores NaN.\n",
      "La columna 'fecha_hora' no tiene valores NaN.\n",
      "La columna 'fecha_hora' no tiene valores NaN.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Hora</th>\n",
       "      <th>ACO</th>\n",
       "      <th>AJM</th>\n",
       "      <th>AJU</th>\n",
       "      <th>ARA</th>\n",
       "      <th>ATI</th>\n",
       "      <th>AZC</th>\n",
       "      <th>BJU</th>\n",
       "      <th>CAM</th>\n",
       "      <th>...</th>\n",
       "      <th>UAX</th>\n",
       "      <th>UIZ</th>\n",
       "      <th>VAL</th>\n",
       "      <th>VIF</th>\n",
       "      <th>XAL</th>\n",
       "      <th>dia</th>\n",
       "      <th>mes</th>\n",
       "      <th>year</th>\n",
       "      <th>fecha_hora</th>\n",
       "      <th>pollutant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-06-2024</td>\n",
       "      <td>00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/06/01 00:00</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-06-2024</td>\n",
       "      <td>01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/06/01 01:00</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-06-2024</td>\n",
       "      <td>02:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/06/01 02:00</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-06-2024</td>\n",
       "      <td>03:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/06/01 03:00</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-06-2024</td>\n",
       "      <td>04:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/06/01 04:00</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35047</th>\n",
       "      <td>30-09-2024</td>\n",
       "      <td>19:00</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/09/30 19:00</td>\n",
       "      <td>WSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35048</th>\n",
       "      <td>30-09-2024</td>\n",
       "      <td>20:00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/09/30 20:00</td>\n",
       "      <td>WSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35049</th>\n",
       "      <td>30-09-2024</td>\n",
       "      <td>21:00</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/09/30 21:00</td>\n",
       "      <td>WSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35050</th>\n",
       "      <td>30-09-2024</td>\n",
       "      <td>22:00</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/09/30 22:00</td>\n",
       "      <td>WSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35051</th>\n",
       "      <td>30-09-2024</td>\n",
       "      <td>23:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024/09/30 23:00</td>\n",
       "      <td>WSP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35052 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Fecha   Hora  ACO   AJM  AJU  ARA   ATI  AZC   BJU  CAM  ...  UAX  \\\n",
       "0      01-06-2024  00:00  NaN  0.14  NaN  NaN  0.76  NaN  0.63  NaN  ...  NaN   \n",
       "1      01-06-2024  01:00  NaN  0.30  NaN  NaN  0.67  NaN  0.77  NaN  ...  NaN   \n",
       "2      01-06-2024  02:00  NaN  0.20  NaN  NaN  0.54  NaN  0.64  NaN  ...  NaN   \n",
       "3      01-06-2024  03:00  NaN  0.14  NaN  NaN  0.61  NaN  0.64  NaN  ...  NaN   \n",
       "4      01-06-2024  04:00  NaN  0.20  NaN  NaN  0.60  NaN  0.55  NaN  ...  NaN   \n",
       "...           ...    ...  ...   ...  ...  ...   ...  ...   ...  ...  ...  ...   \n",
       "35047  30-09-2024  19:00  3.8  4.30  1.9  NaN   NaN  NaN  2.90  NaN  ...  2.1   \n",
       "35048  30-09-2024  20:00  2.5  2.50  2.0  NaN   NaN  NaN  1.30  NaN  ...  1.7   \n",
       "35049  30-09-2024  21:00  2.8  2.30  2.2  NaN   NaN  NaN  2.20  NaN  ...  2.2   \n",
       "35050  30-09-2024  22:00  2.3  2.80  1.7  NaN   NaN  NaN  2.50  NaN  ...  2.5   \n",
       "35051  30-09-2024  23:00  2.0  3.10  1.8  NaN   NaN  NaN  1.60  NaN  ...  2.2   \n",
       "\n",
       "        UIZ  VAL   VIF   XAL  dia  mes  year        fecha_hora  pollutant  \n",
       "0      0.58  NaN  0.80  0.91    1    6  2024  2024/06/01 00:00         CO  \n",
       "1      1.14  NaN  0.70  0.58    1    6  2024  2024/06/01 01:00         CO  \n",
       "2      0.80  NaN  0.61  0.99    1    6  2024  2024/06/01 02:00         CO  \n",
       "3      0.72  NaN  0.71  0.89    1    6  2024  2024/06/01 03:00         CO  \n",
       "4      1.07  NaN  0.73  0.74    1    6  2024  2024/06/01 04:00         CO  \n",
       "...     ...  ...   ...   ...  ...  ...   ...               ...        ...  \n",
       "35047  1.50  NaN   NaN   NaN   30    9  2024  2024/09/30 19:00        WSP  \n",
       "35048  1.30  NaN   NaN   NaN   30    9  2024  2024/09/30 20:00        WSP  \n",
       "35049  1.90  NaN   NaN   NaN   30    9  2024  2024/09/30 21:00        WSP  \n",
       "35050  2.30  NaN   NaN   NaN   30    9  2024  2024/09/30 22:00        WSP  \n",
       "35051  1.90  NaN   NaN   NaN   30    9  2024  2024/09/30 23:00        WSP  \n",
       "\n",
       "[35052 rows x 55 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = \"Archivos_contaminantes_juntas\"\n",
    "dir2 = \"Archivos_contaminantes_juntas2\"\n",
    "#final_filename = \"data_31May_2024_all_stations.csv\"\n",
    "final_filename = \"data_jun_sep_2024_all_stations.csv\"\n",
    "if not os.path.exists(dir2):\n",
    "    os.makedirs(dir2)\n",
    "\n",
    "files = os.listdir(dir)\n",
    "dataframes = []\n",
    "for file_name in files:\n",
    "    file_dir = os.path.join(dir, file_name)\n",
    "    df = pd.read_csv(file_dir, low_memory=False)\n",
    "    df.replace('nr', np.nan, inplace=True)\n",
    "    columns = df.columns\n",
    "    for column in columns:\n",
    "        if 'Unnamed' in column:\n",
    "            df = df.drop(column, axis=1)\n",
    "    df['Fecha'] = df['Fecha'].str.replace('/', '-')\n",
    "    df[['dia', 'mes', 'year']] = df['Fecha'].str.split('-', expand=True)     #separamos la fecha para poder unirla con la hora\n",
    "    df['Hora'] = df['Hora'].replace(24, 0)  #cambiamos las 24 horas por las 0 horas\n",
    "    # Convertir la columna 'horas' al formato de tiempo de Pandas\n",
    "    df['Hora'] = pd.to_datetime(df['Hora'], unit='h')\n",
    "    # Formatear la columna 'horas' en el formato deseado\n",
    "    df['Hora'] = df['Hora'].dt.strftime('%H:%M')\n",
    "    df[\"fecha_hora\"] = df['year'] + \"/\"+df['mes'] +\"/\"+df[\"dia\"]+\" \"+df[\"Hora\"]\n",
    "    df= df.sort_values(by='fecha_hora') \n",
    "    \n",
    "    df[\"pollutant\"] = file_name.split(\".\")[0]\n",
    "    columna_especifica=\"fecha_hora\"\n",
    "    # Verificar si la columna tiene valores NaN\n",
    "    tiene_nan = df[columna_especifica].isnull().any()\n",
    "\n",
    "    # Mostrar el resultado\n",
    "    if tiene_nan:\n",
    "        print(f\"La columna '{columna_especifica}' tiene valores NaN.\")\n",
    "    else:\n",
    "        print(f\"La columna '{columna_especifica}' no tiene valores NaN.\")\n",
    "\n",
    "    file_dir2 = os.path.join(dir2, file_name)\n",
    "    df.to_csv(file_dir2, index=False) \n",
    "    dataframes.append(df)\n",
    "df_final = pd.concat(dataframes, ignore_index=False, sort=False)\n",
    "df_final.to_csv(final_filename, index=False)\n",
    "df = pd.read_csv(final_filename)\n",
    "del df[\"LVI\"]\n",
    "del df[\"SS1\"]\n",
    "if \"Unnamed: 0\" in df.keys():\n",
    "    del df[\"Unnamed: 0\"]\n",
    "df.to_csv(final_filename , index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Fecha', 'Hora', 'ACO', 'AJM', 'AJU', 'ARA', 'ATI', 'AZC', 'BJU', 'CAM',\n",
       "       'CCA', 'CES', 'MON', 'CHO', 'COY', 'CUA', 'CUT', 'FAC', 'FAR', 'GAM',\n",
       "       'HGM', 'IMP', 'INN', 'IZT', 'LAG', 'LLA', 'LPR', 'MER', 'MGH', 'MPA',\n",
       "       'NEZ', 'PED', 'PLA', 'SAC', 'SAG', 'SFE', 'SJA', 'SUR', 'TAC', 'TAH',\n",
       "       'TAX', 'TEC', 'TLA', 'TLI', 'TPN', 'UAX', 'UIZ', 'VAL', 'VIF', 'XAL',\n",
       "       'dia', 'mes', 'year', 'fecha_hora', 'pollutant'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Número de estaciones de las que se tiene información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.keys())-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4\n",
    "\n",
    "## No ejecutar si se hace desde cero (es decir, no hay información antigua con la que juntar la nueva)\n",
    "Unir información nueva con antigua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2005/01/01 00:00\n",
       "1          2005/01/01 01:00\n",
       "2          2005/01/01 02:00\n",
       "3          2005/01/01 03:00\n",
       "4          2005/01/01 04:00\n",
       "                 ...       \n",
       "2015452    2024/05/15 13:00\n",
       "2015453    2024/05/15 14:00\n",
       "2015454    2024/05/15 15:00\n",
       "2015455    2024/05/15 16:00\n",
       "2015456    2024/05/15 17:00\n",
       "Name: fecha_hora, Length: 2015457, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df = pd.read_csv(\"data_15May_2024_all_stations.csv\")\n",
    "old_df[\"fecha_hora\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2024/05/01 00:00\n",
       "1       2024/05/01 01:00\n",
       "2       2024/05/01 02:00\n",
       "3       2024/05/01 03:00\n",
       "4       2024/05/01 04:00\n",
       "              ...       \n",
       "8923    2024/05/31 19:00\n",
       "8924    2024/05/31 20:00\n",
       "8925    2024/05/31 21:00\n",
       "8926    2024/05/31 22:00\n",
       "8927    2024/05/31 23:00\n",
       "Name: fecha_hora, Length: 8928, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = \"data_31May_2024_all_stations.csv\"\n",
    "dir = final_filename\n",
    "df = pd.read_csv(dir)\n",
    "df[\"fecha_hora\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar solo si se tiene información de la parte restante de un mes que ya estaba\n",
    "# Hay que borrar los datos que ya se tienen de ese mes\n",
    "\n",
    "#dir = \"data_31May_2024_all_stations.csv\"\n",
    "dir = final_filename\n",
    "df = pd.read_csv(dir, dtype={'fecha_hora': 'str'})\n",
    "# Convierte la columna 'fecha' a tipo timestamp\n",
    "df['fecha_hora'] = pd.to_datetime(df['fecha_hora'])\n",
    "df['fecha_hora'] = pd.to_datetime(df['fecha_hora'], format='%d/%m/%Y')\n",
    "#df['fecha_hora'] = pd.to_datetime(df['fecha_hora'], format='%Y/%m/%d %H:%M:%S')\n",
    "fecha_limite = pd.Timestamp('2024/05/15 17:00')\n",
    "new_set = df[df['fecha_hora'] > fecha_limite].copy()\n",
    "new_set['fecha_hora'] = new_set['fecha_hora'].dt.strftime('%Y/%m/%d %H:%M')\n",
    "new_set[\"fecha_hora\"]\n",
    "new_set.to_csv(dir, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020137"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(old_df)+len(new_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020137\n"
     ]
    }
   ],
   "source": [
    "df_concat = pd.concat([old_df, new_set])\n",
    "print(len(df_concat))\n",
    "df_concat.to_csv(final_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final_filename = \"all_data_2005xstation_31_05_2024.csv\"\n",
    "#final_filename = \"data_31May_2024_all_stations.csv\"\n",
    "final_filename = \"data_jun_sep_2024_all_stations.csv\"\n",
    "df = pd.read_csv(final_filename)\n",
    "estaciones = df.keys()\n",
    "borrar = ['Fecha', 'Hora', 'dia', 'mes', 'year', 'fecha_hora', 'pollutant']\n",
    "estaciones = [elemento for elemento in estaciones if elemento not in borrar]\n",
    "len(estaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisar los nombres de las carpetas donde se guardarán y de donde se tomarán los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
      "C:\\Users\\valer\\AppData\\Local\\Temp\\ipykernel_20072\\1070152861.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n"
     ]
    }
   ],
   "source": [
    "#dir_to_save = \"datos_por_estacion\"\n",
    "dir_to_save = \"datos_por_estacion_nuevos\"\n",
    "#dir_to_save = \"all_data_2005xstation_31_05_2024\"\n",
    "if not os.path.exists(dir_to_save):\n",
    "    os.makedirs(dir_to_save)\n",
    "    \n",
    "\n",
    "pollutants = [\"CO\", \"NO\", \"NOX\", \"NO2\", \"O3\", \"PM10\", \"PM25\", \"RH\", \"SO2\", \"TMP\", \"WDR\", \"WSP\"]\n",
    "\n",
    "for estacion in estaciones:\n",
    "  columnas_interes = [\"fecha_hora\", \"pollutant\"]\n",
    "  columnas_interes.append(estacion)\n",
    "  datos_modelos = df[columnas_interes]\n",
    "  datos_modelos = datos_modelos.rename(columns={estacion: \"value\"})\n",
    "  dataframes = []\n",
    "  for pollutant in pollutants:\n",
    "    data = datos_modelos[datos_modelos.pollutant==pollutant]\n",
    "    data = data.set_index(\"fecha_hora\")\n",
    "    data.index.name = 'date'\n",
    "    data.drop('pollutant', axis=1, inplace=True)\n",
    "    data = data.rename(columns={\"value\":pollutant})\n",
    "    dataframes.append(data)\n",
    "\n",
    "  df_merged = pd.DataFrame()\n",
    "  columnas = ['date']\n",
    "  df_merged = pd.DataFrame(columns=columnas)\n",
    "  for dataframe in dataframes:\n",
    "    df_merged = pd.merge(df_merged, dataframe, on='date', how='outer')\n",
    "\n",
    "  df_merged = df_merged.reset_index()\n",
    "  df_merged = df_merged.drop(columns=[\"index\"])\n",
    "  df_merged_sin_fecha = df_merged.drop(columns=[\"date\"])\n",
    "  indices_filas_vacias = df_merged_sin_fecha[df_merged_sin_fecha.isna().all(axis=1)].index\n",
    "  df_filtrado = df_merged.drop(indices_filas_vacias)\n",
    "  df_filtrado = df_filtrado.set_index(\"date\")\n",
    "  df_filtrado= df_filtrado.sort_values(by='date') \n",
    "  df_filtrado = df_filtrado.reset_index()\n",
    "  try:\n",
    "    df_filtrado['date'] = df_filtrado['date'].dt.strftime('%Y/%m/%d %H:%M')\n",
    "  #\"\"\"\n",
    "  except:\n",
    "    for i in range(len(df_filtrado)):\n",
    "      try: \n",
    "        fecha = df_filtrado.iloc[i]['date']\n",
    "        if type(fecha) == str: \n",
    "                if len(fecha) == 19:\n",
    "                    # Cambiar el formato de la fecha a 'YYYY/MM/DD HH:MM'\n",
    "                    fecha_dt = datetime.datetime.strptime(fecha, '%Y/%m/%d %H:%M:%S')\n",
    "                    # Formatear la fecha al formato deseado (sin segundos)\n",
    "                    df_filtrado.iloc[i]['date'] = fecha_dt.strftime('%Y/%m/%d %H:%M')\n",
    "                elif len(fecha) == 16:\n",
    "                    #Ya esta con el formato 'YYYY/MM/DD HH:MM'\n",
    "                    df_filtrado.iloc[i]['date'] = pd.to_datetime(fecha, format='%Y/%m/%d %H:%M')\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "        print(i,  type(df_filtrado.iloc[i]['date']))\n",
    "        print(df_filtrado.iloc[i])\n",
    "  #\"\"\"\n",
    "  name = estacion + \".csv\"\n",
    "  dir_file = os.path.join(dir_to_save,name)\n",
    "  df_filtrado.to_csv(dir_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se borran las carpetan que ya no nos sirven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"Archivos_contaminantes_juntas\"\n",
    "shutil.rmtree(dir)\n",
    "dir = \"Archivos_contaminantes_juntas2\"\n",
    "shutil.rmtree(dir)\n",
    "#dir = \"datos_por_estacion\"\n",
    "#shutil.rmtree(dir)\n",
    "\n",
    "#os.remove(final_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
